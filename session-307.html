<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Recent Advances in Data Assimilation and Uncertainty Quantification - Part I of II</h2><div class='index-talk' id='talk1390' style='display:block'><a href='javascript:toggle_star(1390)' class='star'><span class='star1390'>&star;</span></a> <b>1:50 PM&ndash;2:05 PM (Auditorium)</b> Vishwas Rao, Efficient Randomization Techniques for Solving Bayesian Inverse Problems <span id='bitlink-1281'><small><a href='javascript:show_bit(1281)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1281' style='display:none'><small><a href='javascript:hide_bit(1281)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Efficient Randomization Techniques for Solving Bayesian Inverse Problems</b><br />Vishwas Rao<br />Wednesday, March 1 1:50 PM&ndash;2:05 PM<br />This is the 1st talk in <a href='session-307.html'>Recent Advances in Data Assimilation and Uncertainty Quantification - Part I of II</a> (1:50 PM&ndash;3:30 PM)<br />Auditorium<br /><br /><small>Large-scale inverse problems involve fusing incomplete and noisy information from multiple sources, such as model simulations, measurements from sensors, and physical experiments, to obtain a consistent description of the state of the underlying physical system. Solving the Bayesian formulation of these problems enables quantifying the uncertainties associated with the solution. However, solving Bayesian problems presents a major challenge: Solving Bayesian inverse problems is computationally demanding, often requiring hundreds to thousands of expensive simulations to accurately estimate the parameters and their uncertainties. Randomized algorithms provide an attractive means to reduce the computational cost. In this work, we will explore efficient randomization techniques as a means to develop scalable solvers and pre-conditioners to mitigate the computational costs associated with solving Bayesian inverse problems.     </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75692' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1395' style='display:block'><a href='javascript:toggle_star(1395)' class='star'><span class='star1395'>&star;</span></a> <b>2:10 PM&ndash;2:25 PM (Auditorium)</b> Aimee Maurais, Riemannian Multifidelity Covariance Estimation from Statistically Coupled Observations <span id='bitlink-1283'><small><a href='javascript:show_bit(1283)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1283' style='display:none'><small><a href='javascript:hide_bit(1283)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Riemannian Multifidelity Covariance Estimation from Statistically Coupled Observations</b><br />Aimee Maurais<br />Wednesday, March 1 2:10 PM&ndash;2:25 PM<br />This is the 2nd talk in <a href='session-307.html'>Recent Advances in Data Assimilation and Uncertainty Quantification - Part I of II</a> (1:50 PM&ndash;3:30 PM)<br />Auditorium<br /><br /><small>We present a framework for multifidelity covariance estimation from statistically coupled pairs of high- and low-fidelity random variables. We define a multifidelity covariance estimator as the solution to a regression problem on tangent spaces to product manifolds of symmetric positive definite (SPD) matrices. Given a set of high- and low-fidelity sample covariance matrices, viewed as a sample of a product-manifold-valued random variable, we estimate the underlying true covariance matrices by minimizing a notion of squared Mahalanobis distance between the data and a model for its variation about its mean. This estimator can be employed using any Riemannian geometry for the SPD manifold and reduces to control variates in the chosen geometry when all low-fidelity optimization variables are fixed. We particularly focus on the affine-invariant SPD manifold geometry, under which multifidelity covariance regression estimates are guaranteeably positive definite and the Mahalanobis distance has desirable properties. We demonstrate under three geometries that our estimator can provide significant reductions in MSE relative to single-fidelity covariance estimators. This framework is relevant to the data assimilation setting, which often requires repeated evaluation of expensive high-fidelity forecast models, and particularly applicable to the ensemble Kalman filter, in which covariances must be computed from forecast model evaluations in order to perform the analysis step.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75692' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1396' style='display:block'><a href='javascript:toggle_star(1396)' class='star'><span class='star1396'>&star;</span></a> <b>2:30 PM&ndash;2:45 PM (Auditorium)</b> Julie Bessac, Parameter Estimation with Convolutional Neural Networks Applied to An ODE and a Maximum Likelihood Problem <span id='bitlink-1284'><small><a href='javascript:show_bit(1284)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1284' style='display:none'><small><a href='javascript:hide_bit(1284)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Parameter Estimation with Convolutional Neural Networks Applied to An ODE and a Maximum Likelihood Problem</b><br />Julie Bessac<br />Wednesday, March 1 2:30 PM&ndash;2:45 PM<br />This is the 3rd talk in <a href='session-307.html'>Recent Advances in Data Assimilation and Uncertainty Quantification - Part I of II</a> (1:50 PM&ndash;3:30 PM)<br />Auditorium<br /><br /><small>Many inverse problems include poorly behaved objective functions or computationally infeasible likelihood functions such as for multidimensional extremes, thus making traditional approaches for computational recovery of model parameters intractable. We propose a deep learning framework to estimate parameters of two models respectively governed by ordinary differential equations and statistical models for multidimensional extremes. In both cases, we use data from model simulations as input to train deep neural networks and learn the output ODE/statistical parameters. Our neural network-based method provides a competitive alternative to existing methods such as pairwise likelihood for multidimensional extremes, as demonstrated by considerable accuracy and computational time improvements.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75692' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1397' style='display:block'><a href='javascript:toggle_star(1397)' class='star'><span class='star1397'>&star;</span></a> <b>2:50 PM&ndash;3:05 PM (Auditorium)</b> Peter Jan van Leeuwen, Unbiased Filtering and Smoothing for Very High-Dimensional Geophysical Systems: Stochastic Particle Flows <span id='bitlink-1285'><small><a href='javascript:show_bit(1285)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1285' style='display:none'><small><a href='javascript:hide_bit(1285)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Unbiased Filtering and Smoothing for Very High-Dimensional Geophysical Systems: Stochastic Particle Flows</b><br />Peter Jan van Leeuwen<br />Wednesday, March 1 2:50 PM&ndash;3:05 PM<br />This is the 4th talk in <a href='session-307.html'>Recent Advances in Data Assimilation and Uncertainty Quantification - Part I of II</a> (1:50 PM&ndash;3:30 PM)<br />Auditorium<br /><br /><small>Particle Flow Filters and Smoothers allow for sampling posterior probability density functions (pdf) in very high-dimensional spaces. They are based on iterative minimization of the KL-divergence (or other distance measures) between the pdf represented by the particles and the posterior pdf. The methodology can be seen as an ensemble of 3Dvars for a filter, and an ensemble of 4Dvars for a smoother, in which the particles interact during the minimization. Unfortunately, deterministic particle flows are biased for finite ensemble sizes. Recently it has been realized that this bias disappears for any ensemble size when a stochastic version of the particle flow is used. The idea is to consider the flow as a Langevin dynamics over the configuration space spanned by the particles. This leads to an extra stochastic term in the minimization equations, which turns out to be relatively simple to implement. A further problem is that particle flow filters need the gradient of the log of the prior pdf, which is only know by its samples. Hence calculating its log gradient is problematic. We developed a practical solution to this problem of estimating the gradient of the log of the prior in high-dimensional sequential applications, using kernel methods and localization procedures.    
In this talk I will briefly explain the theory and present results of particle flow filters and smoothers for high-dimensional geophysical systems, comparing stochastic and deterministic versions.       </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75692' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1393' style='display:block'><a href='javascript:toggle_star(1393)' class='star'><span class='star1393'>&star;</span></a> <b>3:10 PM&ndash;3:25 PM (Auditorium)</b> Josie K&#246;nig, Time-Limited Balanced Truncation for Data Assimilation <span id='bitlink-1282'><small><a href='javascript:show_bit(1282)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1282' style='display:none'><small><a href='javascript:hide_bit(1282)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Time-Limited Balanced Truncation for Data Assimilation</b><br />Josie K&#246;nig<br />Wednesday, March 1 3:10 PM&ndash;3:25 PM<br />This is the 5th talk in <a href='session-307.html'>Recent Advances in Data Assimilation and Uncertainty Quantification - Part I of II</a> (1:50 PM&ndash;3:30 PM)<br />Auditorium<br /><br /><small>Balanced truncation is a well-established model order reduction concept in system theory that has been applied to a variety of problems. Recently, a connection between linear Gaussian Bayesian inference problems and the system theoretic concept of balanced truncation was drawn for the first time. Although this connection is new, the application of balanced truncation to data assimilation is not a novel concept: It has already been used in four-dimensional variational data assimilation (4D-Var) in its discrete formulation. In our work, the link between system theory and data assimilation is further strengthened by discussing the application of balanced truncation to standard linear Gaussian Bayesian inference, and, in particular, the 4D-Var method. Similarities between both data assimilation problems allow a discussion of established methods as well as a generalisation of the state-of-the-art approach to arbitrary prior covariances as reachability Gramians. Furthermore, we propose an enhanced approach that allows to balance Bayesian inference for unstable systems and improves the numerical results for short observation periods.  	  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75692' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
