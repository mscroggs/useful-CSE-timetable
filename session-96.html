<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Mixed Precision Algorithms in Numerical Linear Algebra - Part II of II</h2><div class='index-talk' id='talk431' style='display:block'><a href='javascript:toggle_star(431)' class='star'><span class='star431'>&star;</span></a> <b>2:35 PM&ndash;2:50 PM (D406)</b> Yuhsiang M. Tsai, Mixed Precision Algebraic Multigrid on GPUs <span id='bitlink-399'><small><a href='javascript:show_bit(399)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-399' style='display:none'><small><a href='javascript:hide_bit(399)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Mixed Precision Algebraic Multigrid on GPUs</b><br />Yuhsiang M. Tsai<br />Thursday, March 2 2:35 PM&ndash;2:50 PM<br />This is the 1st talk in <a href='session-96.html'>Mixed Precision Algorithms in Numerical Linear Algebra - Part II of II</a> (2:35 PM&ndash;4:15 PM)<br />D406<br /><br /><small>We present the first GPU-native platform-portable algebraic multigrid (AMG) implementation that allows the user to use different precision formats for the distinct multigrid levels. The AMG we present uses an aggregation size 2 parallel graph match as the AMG coarsening strategy. The implementation provides a high level of flexibility in terms of configuring the bottom-level solver and the precision format for the distinct levels. We present convergence and performance results on the GPUs from AMD, Intel, and NVIDIA, and compare against corresponding functionality available in other libraries.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75367' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk432' style='display:block'><a href='javascript:toggle_star(432)' class='star'><span class='star432'>&star;</span></a> <b>2:55 PM&ndash;3:10 PM (D406)</b> Rom&#233;o Molina, Adaptive Precision Sparse Iterative Solvers <span id='bitlink-400'><small><a href='javascript:show_bit(400)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-400' style='display:none'><small><a href='javascript:hide_bit(400)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Adaptive Precision Sparse Iterative Solvers</b><br />Rom&#233;o Molina<br />Thursday, March 2 2:55 PM&ndash;3:10 PM<br />This is the 2nd talk in <a href='session-96.html'>Mixed Precision Algorithms in Numerical Linear Algebra - Part II of II</a> (2:35 PM&ndash;4:15 PM)<br />D406<br /><br /><small>We introduce a mixed precision algorithm for computing sparse    matrix-vector products and use it to accelerate the solution of sparse    linear systems by iterative methods. Our approach is based on the idea    of adapting the precision of each matrix element to their magnitude: we    split the elements into buckets and use progressively lower precisions    for the buckets of progressively smaller elements. We carry out a    rounding error analysis of this algorithm that provides us with an    explicit rule to decide which element goes into which bucket and allows    us to rigorously control the accuracy of the algorithm. We implement the    algorithm on a multicore computer and obtain significant speedups (up to    a factor $7\times$) with respect to uniform precision algorithms, without loss of accuracy, on a range of sparse matrices    from real-life applications. We showcase the effectiveness of our    algorithm by plugging it into a GMRES solver for sparse linear systems    and observe that the convergence of the solution is essentially    unaffected by the use of adaptive precision.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75367' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk433' style='display:block'><a href='javascript:toggle_star(433)' class='star'><span class='star433'>&star;</span></a> <b>3:15 PM&ndash;3:30 PM (D406)</b> Daniel R. Bielich, Mixed Precision in Pivoting Avoiding QR <span id='bitlink-401'><small><a href='javascript:show_bit(401)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-401' style='display:none'><small><a href='javascript:hide_bit(401)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Mixed Precision in Pivoting Avoiding QR</b><br />Daniel R. Bielich<br />Thursday, March 2 3:15 PM&ndash;3:30 PM<br />This is the 3rd talk in <a href='session-96.html'>Mixed Precision Algorithms in Numerical Linear Algebra - Part II of II</a> (2:35 PM&ndash;4:15 PM)<br />D406<br /><br /><small>Rank-deficiency plagues least-squares problems. While the QR factorization with Column Pivoting (QRCP) offers a robust solution, it suffers from scaling issues due to its communication-bound nature. The Pivoting Avoiding QR factorization (PAQR) is an alternative that benefits from a scaling similar to that of the original QR factorization but at the expense of fewer theoretical guarantees compared to QRCP. We show how the application in different precisions aids in retaining the speed of a traditional QR factorization, while still selecting an appropriate column order. Within PAQR, there exists a tolerance parameter (used to detect any possible deficiency) that influences the algorithm's behavior, this parameter can be selected so as to fit the accuracy of FP32 or FP16 arithmetic. In this talk we investigate the use of lower-precisions and mixed precisions using PAQR in the context of deficient least-squares problems.    
  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75367' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk434' style='display:block'><a href='javascript:toggle_star(434)' class='star'><span class='star434'>&star;</span></a> <b>3:35 PM&ndash;3:50 PM (D406)</b> Matthieu Robeyns, Mixed Precision Iterative Refinement for Low-Rank Matrix and Tensor Approximations <span id='bitlink-402'><small><a href='javascript:show_bit(402)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-402' style='display:none'><small><a href='javascript:hide_bit(402)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Mixed Precision Iterative Refinement for Low-Rank Matrix and Tensor Approximations</b><br />Matthieu Robeyns<br />Thursday, March 2 3:35 PM&ndash;3:50 PM<br />This is the 4th talk in <a href='session-96.html'>Mixed Precision Algorithms in Numerical Linear Algebra - Part II of II</a> (2:35 PM&ndash;4:15 PM)<br />D406<br /><br /><small>We present a new mixed precision algorithm to compute low-rank matrix and tensor approximations, a fundamental task in numerous applications in scientific computing and data analysis. Our algorithm is reminiscent of the iterative refinement framework for linear systems : we first compute a low-rank approximation in low precision and then refine its accuracy by iteratively updating it. We carry out an error analysis of our algorithm which proves that we can reach a high accuracy while performing most of the operations in low precision. We measure the cost of the algorithm depending on the numerical rank of the input as well as the speed ratio between low and high precision arithmetic. We identify two situations where our method has a strong potential : when the hardware provides fast low precision matrix-multiply-accumulate units, and when the numerical rank of the input is small at low accuracy levels. We assess the potential of our algorithm for computing various low-rank matrix and tensor decompositions such as SVD, QR, Tucker, hierarchical Tucker, and tensor-train.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75367' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk435' style='display:block'><a href='javascript:toggle_star(435)' class='star'><span class='star435'>&star;</span></a> <b>3:55 PM&ndash;4:10 PM (D406)</b> Takeshi Fukaya, An Attempt of Exploiting Low Precision Computing in the GMRES(m) Method <span id='bitlink-403'><small><a href='javascript:show_bit(403)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-403' style='display:none'><small><a href='javascript:hide_bit(403)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>An Attempt of Exploiting Low Precision Computing in the GMRES(m) Method</b><br />Takeshi Fukaya<br />Thursday, March 2 3:55 PM&ndash;4:10 PM<br />This is the 5th talk in <a href='session-96.html'>Mixed Precision Algorithms in Numerical Linear Algebra - Part II of II</a> (2:35 PM&ndash;4:15 PM)<br />D406<br /><br /><small>Recently, the use of low precision computing such as FP16 has attracted much attention. We have studied approaches of accelerating the computations in numerical linear algebra, e.g., solution process of sparse and large liner systems. In this presentation, we show our attempt of introducing low precision computing into the GMRES(m) method, which is one of well-known Krylov subspace methods for non-symmetric problems. First, we present numerical results of a mixed precision variant of the GMRES(m) method using FP64 and FP32. We discuss the behavior of the mixed precision GMRES(m) method and its potential to accelerate the solution process. Second, we consider introducing lower precision computing than FP32 into the GMRES(m) method. We implement different variants of the mixed precision GMRES(m) method and examine their behavior. Through the numerical experiments, we investigate the possibility of aggressively using the lower precision computing in the GMRES(m) method and discuss issues for further performance improvement.   </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75367' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
