<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Approximate Computing for Scientific Applications - Part II of II</h2><div class='index-talk' id='talk1219' style='display:block'><a href='javascript:toggle_star(1219)' class='star'><span class='star1219'>&star;</span></a> <b>4:45 PM&ndash;5:00 PM (G104)</b> David E. Keyes, Low Rank (Almost) Everywhere <span id='bitlink-1130'><small><a href='javascript:show_bit(1130)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1130' style='display:none'><small><a href='javascript:hide_bit(1130)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Low Rank (Almost) Everywhere</b><br />David E. Keyes<br />Thursday, March 2 4:45 PM&ndash;5:00 PM<br />This is the 1st talk in <a href='session-268.html'>Approximate Computing for Scientific Applications - Part II of II</a> (4:45 PM&ndash;6:25 PM)<br />G104<br /><br /><small>Tile low rank and hierarchical low rank matrices can exploit the data sparsity that is discoverable all across computational science: integral equations, differential equations (Schur complements), spatial statistics (covariances), optimization (Hessians), data compression, RBF-based meshing, non-Fickian diffusion, and in various applications such as seismic redatuming, acoustic scattering, adaptive optics, climate and weather predictions, and more. Exploiting data sparsity can improve performance dramatically by allowing the working set to dwell higher in the memory hierarchy than for dense algorithmic counterparts. We illustrate in large-scale applications and hybridize with similarly motivated mixed precision representations, while featuring recent research with many collaborators, including a multi-institutional 2022 Gordon Bell finalist paper.    
    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75608' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1220' style='display:block'><a href='javascript:toggle_star(1220)' class='star'><span class='star1220'>&star;</span></a> <b>5:05 PM&ndash;5:20 PM (G104)</b> Enrique S. Quintana-Orti, Portable Mixed Precision for the Iterative Solution of Sparse Linear Systems <span id='bitlink-1131'><small><a href='javascript:show_bit(1131)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1131' style='display:none'><small><a href='javascript:hide_bit(1131)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Portable Mixed Precision for the Iterative Solution of Sparse Linear Systems</b><br />Enrique S. Quintana-Orti<br />Thursday, March 2 5:05 PM&ndash;5:20 PM<br />This is the 2nd talk in <a href='session-268.html'>Approximate Computing for Scientific Applications - Part II of II</a> (4:45 PM&ndash;6:25 PM)<br />G104<br /><br /><small>The convention in scientific computing is to employ IEEE double-precision (64-bit) arithmetic for all computations involving floating-point data. Nonetheless, appealing benefits from the adoption of mixed precision schemes have been reported for the solution of dense and sparse linear systems, on variety of computer architectures, via iterative refinement. In this talk, we will illustrate the benefits of leveraging mixed precision in terms of execution time and energy efficiency. For this purpose, we will target several case studies arising in the iterative solution of sparse linear systems on GPUs, with codes currently integrated the Ginkgo library (https://ginkgo-project.github.io). In some detail, this research effort exploits the fact that, for sparse linear algebra operations, the cost is dominated by the memory accesses while the arithmetic is largely irrelevant. To leverage this property, the Ginkgo solvers store certain parts of the data in reduced precision in memory, but operate in "full" 64-bit precision in order to bound the accumulation of rounding errors. Reduced-precision storage can be then exploited to maintain approximation operators, such as the preconditioner, or in a GMRES-based solver that adjust the precision of the basis to the problem.    
  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75608' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1221' style='display:block'><a href='javascript:toggle_star(1221)' class='star'><span class='star1221'>&star;</span></a> <b>5:25 PM&ndash;5:40 PM (G104)</b> Damien Gratadour, Mixed Precision Linear Algebra for High Fidelity Real-Time Wavefront Reconstruction on Giant Optical Telescopes <span id='bitlink-1132'><small><a href='javascript:show_bit(1132)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1132' style='display:none'><small><a href='javascript:hide_bit(1132)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Mixed Precision Linear Algebra for High Fidelity Real-Time Wavefront Reconstruction on Giant Optical Telescopes</b><br />Damien Gratadour<br />Thursday, March 2 5:25 PM&ndash;5:40 PM<br />This is the 3rd talk in <a href='session-268.html'>Approximate Computing for Scientific Applications - Part II of II</a> (4:45 PM&ndash;6:25 PM)<br />G104<br /><br /><small>While the largest ground-based telescopes will soon reach 40m diameter to provide means required to detect faint rocky exoplanets, they must overcome optical distortions induced by atmospheric turbulence. This is done thanks to Adaptive Optics (AO) employing a real-time controller (RTC), operating at high speed (1kHz) to catch up with the rapidly changing optical turbulence, and responsible for reconstructing aberrations measured by wavefront sensors (WFS) to drivel deformable mirrors (DM) actuators used to compensate them. In particular Multi-Conjugate AO uses tomographic reconstruction in a linear control scheme: input measurements from several sensors are multiplied by a control matrix to produce an output command vector to drive several DMs. In this context, I will present the various avenues for leveraging approximate computing within the AO RTC. Taking benefit from sensors data coarse grain quantization, mixed precision approximations can be used in the real-time control loop to minimize the servo lag and maximize AO end-to-end performance. Additionally, whilst the tomographic reconstructor must be updated in quasi-real-time, the associated computational burden can be significantly relaxed through mixed precision linear algebra, leveraging intrinsic data sparsity from input matrices, with the goal to either come-up with more complex high-fidelity control schemes or optimize the computer system dimensioning with impact on construction, operation and maintenance costs.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75608' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1222' style='display:block'><a href='javascript:toggle_star(1222)' class='star'><span class='star1222'>&star;</span></a> <b>5:45 PM&ndash;6:00 PM (G104)</b> Adel Dabah, Leveraging Half-Precision in Wireless Communication <span id='bitlink-1133'><small><a href='javascript:show_bit(1133)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1133' style='display:none'><small><a href='javascript:hide_bit(1133)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Leveraging Half-Precision in Wireless Communication</b><br />Adel Dabah<br />Thursday, March 2 5:45 PM&ndash;6:00 PM<br />This is the 4th talk in <a href='session-268.html'>Approximate Computing for Scientific Applications - Part II of II</a> (4:45 PM&ndash;6:25 PM)<br />G104<br /><br /><small>Massive Multiple-Input-Multiple-Output is a crucial technology for Next-Generation networks(Next-G). It uses hundreds of antennas at transceivers to exchange data. However, its accurate signal detection relies on solving an NP-hard optimization problem in real-time. In this presentation, we introduce a new GPU-based detection algorithm that demonstrates the positive impact of low-precision arithmetic (FP16, INT16, INT8) and multiple GPUs to achieve next-G latency/scalability/accuracy requirements. Our approach iteratively extends a solution with several symbols representing the best combination out of the aggregated levels. The computation spanning iterations is formulated as a general matrix-matrix multiplication (GEMM) operation to leverage GPU architectures. Preliminary results using A100 GPU show around 2$\times$ time  complexity improvement by exploiting low-precision GEMM arithmetic over the reference FP32 implementation. Our GEMM-based approach turns out to be oblivious to precision loss by reporting similar accuracy using FP32, FP16, and even INT16/INT8 operations. We demonstrate performance scalability using four A100 GPUs, achieving 2.3$\times$ speedup against a single-GPU version.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75608' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
