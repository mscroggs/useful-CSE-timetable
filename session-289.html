<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Krylov and Algebraic Multigrid Solvers at ExaScale</h2><div class='index-talk' id='talk1310' style='display:block'><a href='javascript:toggle_star(1310)' class='star'><span class='star1310'>&star;</span></a> <b>9:45 AM&ndash;10:00 AM (D506)</b> Gerald Collom, Optimizing Hypre Communication with Node Aware Parallelism <span id='bitlink-1210'><small><a href='javascript:show_bit(1210)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1210' style='display:none'><small><a href='javascript:hide_bit(1210)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Optimizing Hypre Communication with Node Aware Parallelism</b><br />Gerald Collom<br />Thursday, March 2 9:45 AM&ndash;10:00 AM<br />This is the 1st talk in <a href='session-289.html'>Krylov and Algebraic Multigrid Solvers at ExaScale</a> (9:45 AM&ndash;11:25 AM)<br />D506<br /><br /><small>Hypre is an industry-leading, high-performance solver for sparse system of  equations. To perform communication during sparse matrix-vector   multiplication and sparse matrix-matrix multiplication, Hypre uses MPI in a   basic way using only non-blocking sends and receives. Neighborhood   collectives are an alternative communication interface in MPI that provide   more context than a single message enabling the use of this context to   optimize communication within MPI. This work explores optimizing   point-to-point communication in Hypre through the use of neighborhood  collectives and investigates the effects of locality-aware optimizations.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75648' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1311' style='display:block'><a href='javascript:toggle_star(1311)' class='star'><span class='star1311'>&star;</span></a> <b>10:05 AM&ndash;10:20 AM (D506)</b> Carlo Janna, Chronos: a Gpu-Accelerated General Purpose AMG Solver for Industrial Applications <span id='bitlink-1211'><small><a href='javascript:show_bit(1211)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1211' style='display:none'><small><a href='javascript:hide_bit(1211)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Chronos: a Gpu-Accelerated General Purpose AMG Solver for Industrial Applications</b><br />Carlo Janna<br />Thursday, March 2 10:05 AM&ndash;10:20 AM<br />This is the 2nd talk in <a href='session-289.html'>Krylov and Algebraic Multigrid Solvers at ExaScale</a> (9:45 AM&ndash;11:25 AM)<br />D506<br /><br /><small>Algebraic Multigrid (AMG) is a very popular iterative method used in several applications. This wide diffusion is due to its effectiveness in solving linear systems arising from PDE discretizations. The key feature of AMG is its optimality, i.e., the ability to guarantee a convergence rate independent of the mesh size for different problems. This is obtained through a good interplay between the smoother and the interpolation. Unfortunately, for difficult problems, such as those arising in industrial applications, standard AMG techniques are not effective and more elaborate strategies and algorithms need to be developed. The implementation of novel AMG methods became even more difficult with the advent of many-core hardware such as GPU accelerators. While AMG application simply consists in matrix by vector products that have been already successfully ported on GPU by a number of authors, the set-up stage needs to be completely re-designed. In this work, we present the AMG preconditioner included in Chronos, tailored for industrial applications from both solid mechanics and CFD and entirely running on GPU. Thanks to some numerical experiments we will show its performance and scalability on real-world problems.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75648' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1312' style='display:block'><a href='javascript:toggle_star(1312)' class='star'><span class='star1312'>&star;</span></a> <b>10:25 AM&ndash;10:40 AM (D506)</b> Matthias Bolten, Multigrid Methods for Structured Matrices at ExaScale <span id='bitlink-1212'><small><a href='javascript:show_bit(1212)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1212' style='display:none'><small><a href='javascript:hide_bit(1212)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Multigrid Methods for Structured Matrices at ExaScale</b><br />Matthias Bolten<br />Thursday, March 2 10:25 AM&ndash;10:40 AM<br />This is the 3rd talk in <a href='session-289.html'>Krylov and Algebraic Multigrid Solvers at ExaScale</a> (9:45 AM&ndash;11:25 AM)<br />D506<br /><br /><small>Not only with the advent of exascale systems the specific requirements of these machines have become apparent. Developers of simulation codes and numerical methods are confronted not just with a tremendous amount of parallelism but also with a high degree of heterogeneity, hierarchies in networking and memory and challenging programming models. To face these problems we focus on algebraic multigrid methods for structured matrices. In these we use the level hierarchy naturally present in the system matrices while using advanced results from numerical linear algebra to design optimal components for these matrices. The presence of structure not only allows us to obtain the hierarchy straightforwardly, it also eases the efficient implementation on modern computer architectures, including accelerators like GPUs. Nevertheless, even with efficient implementations, the methods' performance is still memory bound. Certain approaches like higher order discretization, but also techniques from linear algebra like block smoothers or polynomial smoothers, can increase the arithmetic intensity and thus reduce the effect of this memory boundedness.    
In the talk an overview over the approach will be given, some recent findings from numerical linear algebra will be presented and the efficient implementation as well as methods to overcome the implications of modern computer architectures will be discussed.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75648' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1313' style='display:block'><a href='javascript:toggle_star(1313)' class='star'><span class='star1313'>&star;</span></a> <b>10:45 AM&ndash;11:00 AM (D506)</b> Amik St Cyr, Schwarz Smoothers for Pressure Projection in low-Mach Navier-Stokes Combustion Models <span id='bitlink-1213'><small><a href='javascript:show_bit(1213)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1213' style='display:none'><small><a href='javascript:hide_bit(1213)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Schwarz Smoothers for Pressure Projection in low-Mach Navier-Stokes Combustion Models</b><br />Amik St Cyr<br />Thursday, March 2 10:45 AM&ndash;11:00 AM<br />This is the 4th talk in <a href='session-289.html'>Krylov and Algebraic Multigrid Solvers at ExaScale</a> (9:45 AM&ndash;11:25 AM)<br />D506<br /><br /><small>PeleLM is an adaptive mesh low Mach Navier-Stokes combustion   code developed under DOE's Exascale Computing Program.    A key feature of the model is that the fluid density varies considerably across the computational domain. Extremely ill-conditioned problems arise for incompressible and reacting flows in the low Mach flow regime, particularly for cut-cell meshes in complex geometries, where non-covered cells that are cut by the domain boundar have arbitrarily small volumes and areas.  The standard Jacobi and Gauss-Seidel AMG smoothers are less effective in these cases at reducing the error at each level of the AMG $V$-cycle and may   result in very large iteration counts for the GMRES+AMG solver.    
Prenter (2020) improved convergence rates for cut-cells and  conjugate-gradient solvers with AMG preconditioners by employing Schwarz  smoothers. We combine ILU smoothers using iterative triangular solves with  restricted additive Schwarz (RAS) adapted to hypre for a new iterated   Gauss-Seidel formulation of GMRES with AMG preconditioner.   The iteration counts tend to remain constant and these smoothers reduce run times on many-core GPU's in the strong-scaling limit.    
    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75648' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1314' style='display:block'><a href='javascript:toggle_star(1314)' class='star'><span class='star1314'>&star;</span></a> <b>11:05 AM&ndash;11:20 AM (D506)</b> Cl&#233;ment Richefort, Multigrid Method for the Indefinite Helmholtz Equation <span id='bitlink-1214'><small><a href='javascript:show_bit(1214)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1214' style='display:none'><small><a href='javascript:hide_bit(1214)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Multigrid Method for the Indefinite Helmholtz Equation</b><br />Cl&#233;ment Richefort<br />Thursday, March 2 11:05 AM&ndash;11:20 AM<br />This is the 5th talk in <a href='session-289.html'>Krylov and Algebraic Multigrid Solvers at ExaScale</a> (9:45 AM&ndash;11:25 AM)<br />D506<br /><br /><small>It is well known that multigrid methods are very competitive in solving a wide range of SPD problems. However achieving such performance for non-SPD matrices remains an open problem. In particular, two main issues may arise when solving a Helmholtz problem. Some eigenvalues become negative or even complex, requiring the choice of an adapted smoothing method for capturing them. Moreover, since the near-kernel space is oscillatory, the geometric smoothness assumption cannot be used to build efficient interpolation rules. We present some investigations about designing a method that converges in a constant number of iterations with respect to the wavenumber. The method builds on an ideal reduction-based framework and related theory for SPD matrices to correct an initial least squares minimization coarse selection operator formed from a set of smoothed random vectors.      
    
    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75648' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
