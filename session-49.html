<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>High-Performance Computing in the FASTMath SciDAC-5 Institute - Part II of II</h2><div class='index-talk' id='talk222' style='display:block'><a href='javascript:toggle_star(222)' class='star'><span class='star222'>&star;</span></a> <b>4:00 PM&ndash;4:15 PM (Emerald Room)</b> Doru Thom A. Popovici, Can Planewave DFT Codes Scale on Massively Parallel GPU-Based Supercomputers? <span id='bitlink-206'><small><a href='javascript:show_bit(206)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-206' style='display:none'><small><a href='javascript:hide_bit(206)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Can Planewave DFT Codes Scale on Massively Parallel GPU-Based Supercomputers?</b><br />Doru Thom A. Popovici<br />Wednesday, March 1 4:00 PM&ndash;4:15 PM<br />This is the 1st talk in <a href='session-49.html'>High-Performance Computing in the FASTMath SciDAC-5 Institute - Part II of II</a> (4:00 PM&ndash;5:40 PM)<br />Emerald Room<br /><br /><small>In the age of exascale computing, scientific simulations must make use of massively parallel GPU-based supercomputers. For example, two of the top supercomputers, Summit and Frontier, offer huge amounts of computing capabilities meant to enable scientists to execute bigger scientific problems in shorter amounts of time. However, these new systems require existing scientific software to be re-designed and re-implemented to fully utilize the hardware features. Previous assumptions that made software execute efficiently on the supercomputers from 10 years ago, may not comply with recent hardware capabilities. In this work, we will focus on re-designing some algorithms that are heavily used in Planewave Density Functional Theory (DFT) simulations. More specifically, we will focus on four algorithms meant to solve a non-linear eigenvalue problem, namely Conjugate Gradient, DIIS, Jacobi Davidson and Unconstrained. For each method we identify the bottlenecks, and devise strategies to overcome the issues and scale the codes to thousands of GPUs. We will highlight the similarities and differences between the four algorithms using our approach. In addition, we will compare the codes against the theoretical machine peak and discuss each implementation in detail.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75275' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk223' style='display:block'><a href='javascript:toggle_star(223)' class='star'><span class='star223'>&star;</span></a> <b>4:20 PM&ndash;4:35 PM (Emerald Room)</b> Ulrike Meier Yang, Recent Advances in Hypre to Support Exascale Computers <span id='bitlink-207'><small><a href='javascript:show_bit(207)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-207' style='display:none'><small><a href='javascript:hide_bit(207)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Recent Advances in Hypre to Support Exascale Computers</b><br />Ulrike Meier Yang<br />Wednesday, March 1 4:20 PM&ndash;4:35 PM<br />This is the 2nd talk in <a href='session-49.html'>High-Performance Computing in the FASTMath SciDAC-5 Institute - Part II of II</a> (4:00 PM&ndash;5:40 PM)<br />Emerald Room<br /><br /><small>With the increasing inclusion of accelerators into current and future high-performance computers, it has become important to enable parallel mathematical libraries to take advantage of the increased performance potential of GPUs. The hypre software library provides high performance preconditioners and solvers for the solution of large sparse linear systems on massively parallel computers with focus on algebraic multigrid (AMG) methods. One of its attractive features is the provision of conceptual interfaces, which include a structured, a semi-structured interface, and a traditional linear-algebra-based interface. These interfaces give application users various means for describing their linear systems and provide access to methods such as structured multigrid solvers, which can take advantage of the additional information beyond just the matrix, as well as unstructured multigrid solvers. This talk will discuss new developments in hypre.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75275' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk224' style='display:block'><a href='javascript:toggle_star(224)' class='star'><span class='star224'>&star;</span></a> <b>4:40 PM&ndash;4:55 PM (Emerald Room)</b> Richard T. Mills, Enabling End-to-End Accelerated Simulations in the Exascale Era Using PETSc <span id='bitlink-208'><small><a href='javascript:show_bit(208)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-208' style='display:none'><small><a href='javascript:hide_bit(208)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Enabling End-to-End Accelerated Simulations in the Exascale Era Using PETSc</b><br />Richard T. Mills<br />Wednesday, March 1 4:40 PM&ndash;4:55 PM<br />This is the 3rd talk in <a href='session-49.html'>High-Performance Computing in the FASTMath SciDAC-5 Institute - Part II of II</a> (4:00 PM&ndash;5:40 PM)<br />Emerald Room<br /><br /><small>The Portable Extensible Toolkit for Scientific computation (PETSc) library provides scalable solvers for nonlinear time-dependent differential and algebraic equations and for numerical optimization. Throughout its history, a major goal of PETSc development has been achieving scalability required to fully utilize leadership-class supercomputers. In the past, this meant a great deal of focus on inter-node scalability, but, as we enter the exascale era, the primary challenge to enabling extreme-scale computation has become harnessing abundant fine-scale parallelism within compute nodes -- primarily in the form of GPU-based accelerators. We will discuss how the PETSc design for performance portability addresses these challenges while stressing flexibility and extensibility by separating the programming model used by the application from that used by the library, and we will present some examples of how this facilitates end-to-end utilization of GPUs for PETSc-based simulations on cutting-edge high-performance computing architectures. Additionally, we will discuss recent developments in PETSc's communication module, PetscSF, that enable flexibility and scalable performance across large GPU-based systems while overcoming some of the difficulties posed by working directly with the Message Passing Interface (MPI) on these systems.    
    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75275' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk225' style='display:block'><a href='javascript:toggle_star(225)' class='star'><span class='star225'>&star;</span></a> <b>5:00 PM&ndash;5:15 PM (Emerald Room)</b> Peter McCorquodale, Using the FFTX Library in Applications <span id='bitlink-209'><small><a href='javascript:show_bit(209)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-209' style='display:none'><small><a href='javascript:hide_bit(209)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Using the FFTX Library in Applications</b><br />Peter McCorquodale<br />Wednesday, March 1 5:00 PM&ndash;5:15 PM<br />This is the 4th talk in <a href='session-49.html'>High-Performance Computing in the FASTMath SciDAC-5 Institute - Part II of II</a> (4:00 PM&ndash;5:40 PM)<br />Emerald Room<br /><br /><small>FFTX is a performance-portable, open-source FFT software system for CPUs and GPUs analogous to FFTW for CPU systems. It supports application-specific optimizations corresponding to integrating more of the algorithms into the analysis / code-generation process. FFTX is based on the use of Spiral, an open-source analysis and code-generation tool chain for FFTs and tensor algebra algorithms, developed at Carnegie-Mellon University and SpiralGen, Inc.; an FFTX user API implemented in standard C++; and a factored design that allows FFTX / Spiral to be more easily ported across multiple architectures. In FFTX, we can represent larger integrated algorithms that include FFTs composed with algorithmic operations such as multiplication by a (possibly matrix-valued) symbol and batching. By combining substeps in an integrated algorithm, the amount of data traffic can be reduced by significant amounts. FFTX applies the size-specific analysis and automatic code generation techniques in Spiral to generate code, leading to implementations with far higher performance than obtainable from approaches based on black-box FFT implementations. In this talk, we will demonstrate how to install the FFTX library and use it in applications written in C++ and Python, and present results obtained on supercomputers with NVIDIA and AMD GPU systems.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75275' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
