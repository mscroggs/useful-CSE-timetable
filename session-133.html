<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Recent Advances in Modeling, Simulation, and Sampling via Artificial Intelligence for Physical Sciences and Engineering - Part II of II</h2><div class='index-talk' id='talk606' style='display:block'><a href='javascript:toggle_star(606)' class='star'><span class='star606'>&star;</span></a> <b>1:50 PM&ndash;2:05 PM (G109)</b> Claudio Canuto, Some Mathematical Aspects of PINN-VPINN Discretization of PDEs <span id='bitlink-564'><small><a href='javascript:show_bit(564)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-564' style='display:none'><small><a href='javascript:hide_bit(564)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Some Mathematical Aspects of PINN-VPINN Discretization of PDEs</b><br />Claudio Canuto<br />Monday, February 27 1:50 PM&ndash;2:05 PM<br />This is the 1st talk in <a href='session-133.html'>Recent Advances in Modeling, Simulation, and Sampling via Artificial Intelligence for Physical Sciences and Engineering - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />G109<br /><br /><small>We introduce a Petrov-Galerkin framework to derive rigorous a priori and a posteriori error estimates for VPINN discretizations of elliptic boundary-value problems. The analysis relies on an inf-sup condition between trial and test spaces; this allows us to control the error, in the energy norm, between the exact solution and a suitable high-order piecewise-polynomial interpolant of the computed neural network. The efficiency and accuracy of the computation depends, among other factors, on the way boundary conditions are imposed. We will discuss several options for enforcing Dirichlet or Neumann boundary conditions, and we will compare their behavior for both PINNs and VPINNs, and for various types of equations.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75421' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk607' style='display:block'><a href='javascript:toggle_star(607)' class='star'><span class='star607'>&star;</span></a> <b>2:10 PM&ndash;2:25 PM (G109)</b> Elias Cueto, Thermodynamics-Informed Neural Networks <span id='bitlink-565'><small><a href='javascript:show_bit(565)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-565' style='display:none'><small><a href='javascript:hide_bit(565)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Thermodynamics-Informed Neural Networks</b><br />Elias Cueto<br />Monday, February 27 2:10 PM&ndash;2:25 PM<br />This is the 2nd talk in <a href='session-133.html'>Recent Advances in Modeling, Simulation, and Sampling via Artificial Intelligence for Physical Sciences and Engineering - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />G109<br /><br /><small>In this talk, we review the recent advances in the development of thermodynamics-informed neural networks for learning physical phenomena. These networks work under a dynamical systems analogy and employ inductive biases so as to guarantee the fulfillment of the laws of thermodynamics. While for conservative dynamics a Hamiltonian structure could be a very convenient bias, in the case of dissipative phenomena an alternative description should be used. We employ a metriplectic description coined as GENERIC [Oettinger & Grmela, 1997] that ensure conservation of energy in closed systems and non-negative entropy production. In combination with a Graph Neural Network approach, these networks can even impose by construction translational invariance and other symmetries of the studied systems.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75421' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk608' style='display:block'><a href='javascript:toggle_star(608)' class='star'><span class='star608'>&star;</span></a> <b>2:30 PM&ndash;2:45 PM (G109)</b> Jaeyong Lee, Two Approaches Using Deep Learning to Solve Partial Differential Equations <span id='bitlink-566'><small><a href='javascript:show_bit(566)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-566' style='display:none'><small><a href='javascript:hide_bit(566)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Two Approaches Using Deep Learning to Solve Partial Differential Equations</b><br />Jaeyong Lee<br />Monday, February 27 2:30 PM&ndash;2:45 PM<br />This is the 3rd talk in <a href='session-133.html'>Recent Advances in Modeling, Simulation, and Sampling via Artificial Intelligence for Physical Sciences and Engineering - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />G109<br /><br /><small>Many differential equations and partial differential equations (PDEs) are being studied to model physical phenomena in nature with mathematical expressions. Recently, new numerical approaches using machine learning and deep learning have been actively studied. There are two mainstream deep learning approaches to approximate solutions to the PDEs, i.e., using neural networks directly to parametrize the solution to the PDE and learning operators from the parameters of the PDEs to their solutions. As the first direction, Physics-Informed Neural Network was introduced in (Raissi, Perdikaris, and Karniadakis 2019), which learns the neural network parameters to minimize the PDE residuals in the least-squares sense. On the other side, operator learning using neural networks has been studied to approximate a PDE solution operator, which is nonlinear and complex in general. In this talk, I will introduce these two ways to approximate the solution of PDE and my research related to them.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75421' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk609' style='display:block'><a href='javascript:toggle_star(609)' class='star'><span class='star609'>&star;</span></a> <b>2:50 PM&ndash;3:05 PM (G109)</b> Yeonjong Shin, Accelerating Gradient Descent and Adam via Fractional Gradients <span id='bitlink-567'><small><a href='javascript:show_bit(567)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-567' style='display:none'><small><a href='javascript:hide_bit(567)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Accelerating Gradient Descent and Adam via Fractional Gradients</b><br />Yeonjong Shin<br />Monday, February 27 2:50 PM&ndash;3:05 PM<br />This is the 4th talk in <a href='session-133.html'>Recent Advances in Modeling, Simulation, and Sampling via Artificial Intelligence for Physical Sciences and Engineering - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />G109<br /><br /><small>In this talk, we present a class of novel fractional-order optimization algorithms. As a first step, we define a fractional-order gradient via the Caputo fractional derivatives that generalizes integer-order gradient, which is referred to as the Caputo fractional-based gradient. Then, a general class of fractional-order optimization methods is obtained by replacing integer-order gradients with the Caputo fractional-based gradients. To give concrete algorithms, we consider gradient descent (GD) and Adam, and extend them to the Caputo fractional GD (CfGD) and the Caputo fractional Adam (CfAdam). We demonstrate the superiority of CfGD and CfAdam on several large-scale optimization problems that arise from scientific machine learning applications, such as ill-conditioned least squares problems on real-world data and the training of neural networks involving non-convex objective functions.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75421' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk610' style='display:block'><a href='javascript:toggle_star(610)' class='star'><span class='star610'>&star;</span></a> <b>3:10 PM&ndash;3:25 PM (G109)</b> Sapna Baluni, Quasi Projective Synchronization of Complex Valued Cohen-Grossberg Neural Networks with Time Varying Delay and Mismatched Parameters <span id='bitlink-568'><small><a href='javascript:show_bit(568)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-568' style='display:none'><small><a href='javascript:hide_bit(568)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Quasi Projective Synchronization of Complex Valued Cohen-Grossberg Neural Networks with Time Varying Delay and Mismatched Parameters</b><br />Sapna Baluni<br />Monday, February 27 3:10 PM&ndash;3:25 PM<br />This is the 5th talk in <a href='session-133.html'>Recent Advances in Modeling, Simulation, and Sampling via Artificial Intelligence for Physical Sciences and Engineering - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />G109<br /><br /><small>In this article the quasi-projective synchronization of time-varying delayed complex-valued Cohen Grossberg Neural Networks (CGNNs) with non-identical parameters has been studied. As complete projective synchronization is impossible due to parametersâ€™ mismatches projective coefficient and controller, a drive has been taken to achieve quasi-projective synchronization of distinct complex-valued CGNNs. The purpose of this study is to find a criterion for quasi-projective synchronization of two non-identical CGNNs  by constructing a suitable controller and by using direct method. The important contribution is to estimate the bound on the synchronization error. Some sufficient criteria for synchronization between master and response systems are also established.  The efficiency of the proposed method is justified through numerical simulation applied to a specific example.  	  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75421' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
