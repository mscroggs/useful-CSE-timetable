<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Bayesian Inference and Density Estimation</h2><div class='index-talk' id='talk2047' style='display:block'><a href='javascript:toggle_star(2047)' class='star'><span class='star2047'>&star;</span></a> <b>2:35 PM&ndash;2:50 PM (G111)</b> Alessandro Zocca, Breaking Out of Local Minima: Enhancing the Basin Hopping Algorithm with the Skipping Mechanism <span id='bitlink-1873'><small><a href='javascript:show_bit(1873)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1873' style='display:none'><small><a href='javascript:hide_bit(1873)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Breaking Out of Local Minima: Enhancing the Basin Hopping Algorithm with the Skipping Mechanism</b><br />Alessandro Zocca<br />Thursday, March 2 2:35 PM&ndash;2:50 PM<br />This is the 1st talk in <a href='session-218.html'>Bayesian Inference and Density Estimation</a> (2:35 PM&ndash;4:15 PM)<br />G111<br /><br /><small>The Basin Hopping algorithm is a widely used stochastic method for solving complex global optimization problems, but it can be hindered by getting trapped in local minima. In this talk, I will present a new variant of this algorithm, named Basin Hopping with Skipping (BH-S), in which the classical perturbation step is replaced with a so-called skipping mechanism from rare-event sampling. This new perturbation strategy makes it easier to escape local minima and enhances non-local exploration, leading to a more efficient and effective optimization process.  In this talk, I will provide an in-depth overview of the skipping mechanism, describe its integration into the basin-hopping algorithm, and present some empirical results on benchmark global optimization problems.    
  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75534' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk994' style='display:block'><a href='javascript:toggle_star(994)' class='star'><span class='star994'>&star;</span></a> <b>2:55 PM&ndash;3:10 PM (G111)</b> Josephine Westermann, Transport-Based Sampling Using Polynomial Density Surrogates <span id='bitlink-916'><small><a href='javascript:show_bit(916)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-916' style='display:none'><small><a href='javascript:hide_bit(916)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Transport-Based Sampling Using Polynomial Density Surrogates</b><br />Josephine Westermann<br />Thursday, March 2 2:55 PM&ndash;3:10 PM<br />This is the 2nd talk in <a href='session-218.html'>Bayesian Inference and Density Estimation</a> (2:35 PM&ndash;4:15 PM)<br />G111<br /><br /><small>Generating samples from arbitrary probability distributions is an integral task in various areas of modern applied mathematics such as parameter inference and uncertainty quantification.  In this talk, we describe a sampling algorithm based on the Knothe-Rosenblatt transport, that can be used to approximately   sample from target distributions on the $d$-dimensional unit cube $[0,1]^d$ under mild assumptions on the target density.   The method is based on the use of  polynomial density surrogates, which allows to explicitly and  analytically construct the corresponding transport.   We discuss efficient implementation schemes and derive error convergence rates  for target densities belonging to different smoothness classes.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75534' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk995' style='display:block'><a href='javascript:toggle_star(995)' class='star'><span class='star995'>&star;</span></a> <b>3:15 PM&ndash;3:30 PM (G111)</b> Sergey Dolgov, Deep Importance Sampling Using Tensor Approximations <span id='bitlink-917'><small><a href='javascript:show_bit(917)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-917' style='display:none'><small><a href='javascript:hide_bit(917)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Deep Importance Sampling Using Tensor Approximations</b><br />Sergey Dolgov<br />Thursday, March 2 3:15 PM&ndash;3:30 PM<br />This is the 3rd talk in <a href='session-218.html'>Bayesian Inference and Density Estimation</a> (2:35 PM&ndash;4:15 PM)<br />G111<br /><br /><small>We propose a deep importance sampling method that is suitable in particular for estimating rare event probabilities in high-dimensional problems. We approximate the optimal importance distribution in a general importance sampling problem as the pushforward of a reference distribution under a composition of order-preserving transformations, in which each transformation is formed by a squared tensor-train decomposition of a ratio of unnormalized bridging density functions, such as tempered or smoothed versions of the target density. The use of composition of maps moving along a sequence of bridging densities alleviates the difficulty of directly approximating a concentrated target density function. To compute expectations over unnormalized probability distributions, we design a ratio estimator that estimates the normalizing constant using a separate importance distribution, again constructed via a composition of transformations in tensor-train format. This offers better theoretical variance reduction compared with self-normalized importance sampling, and thus opens the door to efficient computation of rare event probabilities in Bayesian inference problems. Numerical experiments on problems constrained by differential equations show little to no increase in the computational complexity with the event probability going to zero.    
    
    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75534' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk2048' style='display:block'><a href='javascript:toggle_star(2048)' class='star'><span class='star2048'>&star;</span></a> <b>3:35 PM&ndash;3:50 PM (G111)</b> Lukas Trottner, Concentration Analysis of Multivariate Elliptic Diffusions <span id='bitlink-1874'><small><a href='javascript:show_bit(1874)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1874' style='display:none'><small><a href='javascript:hide_bit(1874)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Concentration Analysis of Multivariate Elliptic Diffusions</b><br />Lukas Trottner<br />Thursday, March 2 3:35 PM&ndash;3:50 PM<br />This is the 4th talk in <a href='session-218.html'>Bayesian Inference and Density Estimation</a> (2:35 PM&ndash;4:15 PM)<br />G111<br /><br /><small>We prove concentration inequalities and associated PAC bounds for continuous- and discrete-time additive functionals for possibly unbounded functions of multivariate, nonreversible diffusion processes. Our analysis relies on an approach via the Poisson equation allowing us to consider a very broad class of subexponentially ergodic processes. These results add to existing concentration inequalities for additive functionals of diffusion processes which have so far been only available for either bounded functions or for unbounded functions of processes from a significantly smaller class. We demonstrate the usefulness of the results by applying them in the context of high-dimensional drift estimation and Langevin MCMC for moderately heavy-tailed target densities. This is joint work with Cathrine Aeckerle-Willems and Claudia Strauch.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75534' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk997' style='display:block'><a href='javascript:toggle_star(997)' class='star'><span class='star997'>&star;</span></a> <b>3:55 PM&ndash;4:10 PM (G111)</b> Jonas Nitzler, Bayesian Multifidelity Inverse Analysis for Expensive, Non-Differentiable, Physics-Based Solvers in High Dimensions <span id='bitlink-918'><small><a href='javascript:show_bit(918)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-918' style='display:none'><small><a href='javascript:hide_bit(918)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Bayesian Multifidelity Inverse Analysis for Expensive, Non-Differentiable, Physics-Based Solvers in High Dimensions</b><br />Jonas Nitzler<br />Thursday, March 2 3:55 PM&ndash;4:10 PM<br />This is the 5th talk in <a href='session-218.html'>Bayesian Inference and Density Estimation</a> (2:35 PM&ndash;4:15 PM)<br />G111<br /><br /><small>Computationally expensive, large-scale, numerical models with high-dimensional (stochastic) model input pose some of the biggest challenges for (Bayesian) inverse analysis. The solution process is further impeded when model derivatives are inaccessible, as is often the case in  legacy codes.  We propose Bayesian multifidelity inverse analysis (BMFIA), which overcomes the difficulties mentioned above by employing computationally inexpensive, lower-fidelity models and constructing a multifidelity likelihood function. The approach builds upon previous developments of the authors in the  field of uncertainty quantification. The multifidelity likelihood is learned robustly, and potentially adaptively, from a small number of high-fidelity simulations. It incorporates the epistemic uncertainty that arises from the small amount of high-fidelity data and can also serve as an objective function for deterministic optimization schemes. We enrich the multi-fidelity dependence with low-dimensional, informative input features, which increases the formulation’s accuracy.  The inference process can be performed using state-of-the-art sampling-based or variational methods  for Bayesian inverse analysis and requires only evaluations of the lower-fidelity model(s), which, when appropriately selected, can also furnish derivatives.  We demonstrate our approach on large-scale biomechanical and coupled multi-physics problems and  compare it with state-of-the-art single- and multi-fidelity methods.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75534' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
