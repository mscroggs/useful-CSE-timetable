<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Computational Aspects of Tensor Networks - Part I of II</h2><div class='index-talk' id='talk1338' style='display:block'><a href='javascript:toggle_star(1338)' class='star'><span class='star1338'>&star;</span></a> <b>4:00 PM&ndash;4:15 PM (G105)</b> Edoardo Di Napoli, High-Performance Computing in Tensor Networks: the Current Status and the Challenges Ahead <span id='bitlink-1236'><small><a href='javascript:show_bit(1236)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1236' style='display:none'><small><a href='javascript:hide_bit(1236)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>High-Performance Computing in Tensor Networks: the Current Status and the Challenges Ahead</b><br />Edoardo Di Napoli<br />Wednesday, March 1 4:00 PM&ndash;4:15 PM<br />This is the 1st talk in <a href='session-295.html'>Computational Aspects of Tensor Networks - Part I of II</a> (4:00 PM&ndash;5:40 PM)<br />G105<br /><br /><small>Numerical techniques based on tensor networks has been used in the past twenty years to tackle problems in quantum many-body physics. In recent years, tensor network methods have witnessed applications beyond quantum physics to include quantum circuits, artificial intelligence and lattice gauge theory, just to name a few. This expansion in application domain is accompanied by an increase in the scale of the simulations performed and their computational complexity. In order to address complexity and scale, there have been few initiative towards the introduction of high-performance and parallel computing methods in tensor networks computations. The aim of this contribution is to highlight the current status of HPC in tensor networks and give a measure of some of the challenges ahead, setting the stage for all the contributions to this minisymposium.        </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75656' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1342' style='display:block'><a href='javascript:toggle_star(1342)' class='star'><span class='star1342'>&star;</span></a> <b>4:20 PM&ndash;4:35 PM (G105)</b> Vladimir Kazeev, Low-Rank Tensor Approximation for the Numerical Solution of Elliptic and Parabolic Problems <span id='bitlink-1240'><small><a href='javascript:show_bit(1240)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1240' style='display:none'><small><a href='javascript:hide_bit(1240)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Low-Rank Tensor Approximation for the Numerical Solution of Elliptic and Parabolic Problems</b><br />Vladimir Kazeev<br />Wednesday, March 1 4:20 PM&ndash;4:35 PM<br />This is the 2nd talk in <a href='session-295.html'>Computational Aspects of Tensor Networks - Part I of II</a> (4:00 PM&ndash;5:40 PM)<br />G105<br /><br /><small>Low-rank tensor decompositions are an attractive tool for the numerical solution of differential equations, reducing the complexity of the problem by the adaptive low-parametric approximation using techniques of numerical linear algebra and optimization. We focus on a multilevel approximation scheme based on the tensor decomposition known as matrix product states (MPS) in computational quantum physics and as tensor train (TT) in computational mathematics. This scheme has been shown, both theoretically and experimentally, to efficiently approximate functions with algebraic singularities and highly-oscillatory solutions to multiscale diffusion problems, achieving exponential convergence with respect to the total number of representation parameters.    
We present recent results on the use of the multilevel MPS-TT representation for the numerical solution of elliptic and parabolic PDE problems, which involves the multilevel preconditioning and the iterative solution of resulting linear systems in low-rank form. The approach is based on generic finite-element spaces and amounts to the adaptive computation of a collection of quasi-optimal low-dimensional subspaces. The use of low-rank tensor approximation in combination with robust multilevel preconditioning allows to work with extravagantly large finite-element spaces and leads to data-driven computations with effective discretizations adapted to the data, which contrasts with the use of approximation spaces designed analytically.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75656' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1340' style='display:block'><a href='javascript:toggle_star(1340)' class='star'><span class='star1340'>&star;</span></a> <b>4:40 PM&ndash;4:55 PM (G105)</b> Matteo Rizzi, 2D Tensor Network Optimization via Automatic Differentiation <span id='bitlink-1238'><small><a href='javascript:show_bit(1238)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1238' style='display:none'><small><a href='javascript:hide_bit(1238)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>2D Tensor Network Optimization via Automatic Differentiation</b><br />Matteo Rizzi<br />Wednesday, March 1 4:40 PM&ndash;4:55 PM<br />This is the 3rd talk in <a href='session-295.html'>Computational Aspects of Tensor Networks - Part I of II</a> (4:00 PM&ndash;5:40 PM)<br />G105<br /><br /><small>Two-dimensional quantum many-body systems exhibit some of the most elusive problems in condensed matter physics, whose solution is foreseen to impact material science and information processing. In recent years, practical progress has been made towards finding an approximation to their ground-state(s) by means of tensor-network ansatzes, in particular (infinite) projected entangled pair states (iPEPS). Based on the variational principle, such ground-state search can be formulated as a highly non-linear optimization problem, for which well established gradient-based non-linear optimization strategies like conjugate gradient or quasi-Newton methods could be employed. Computing explicitly the gradient via a plethora of tensor contractions to be programmed case-by-case has traditionally obstructed this approach. Nowadays, algorithmic differentiation has considerably eased the path, and the variational procedure has been demonstrated to yield lower energies and less biased many-body configurations than alternative methods like imaginary-time evolution. Here, we report on our implementation of a flexible and efficient library for this state-of-the-art approach in the programming language Julia, based on the TensorKit package, and we showcase some results on frustrated 2d quantum spin models.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75656' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1341' style='display:block'><a href='javascript:toggle_star(1341)' class='star'><span class='star1341'>&star;</span></a> <b>5:00 PM&ndash;5:15 PM (G105)</b> Karl Pierce, Introduction to the ITensor Software Library for Tensor Network Calculations <span id='bitlink-1239'><small><a href='javascript:show_bit(1239)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1239' style='display:none'><small><a href='javascript:hide_bit(1239)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Introduction to the ITensor Software Library for Tensor Network Calculations</b><br />Karl Pierce<br />Wednesday, March 1 5:00 PM&ndash;5:15 PM<br />This is the 4th talk in <a href='session-295.html'>Computational Aspects of Tensor Networks - Part I of II</a> (4:00 PM&ndash;5:40 PM)<br />G105<br /><br /><small>ITensor is a software library for developing tensor network algorithms. Modeled on tensor diagram notation, ITensor has a unique memory-independent tensor interface which allows users to focus on the connectivity of a tensor network without manually bookkeeping tensor indices. ITensor has primarily been used in applications to quantum many-body physics, but has found applications in a variety of fields such as quantum computing, machine learning, chemistry, and differential equations. Here we will introduce the ITensor interface and discuss recent advancements in the library such as multithreaded block sparse operations, general tensor network optimization, GPU support, and more as time allows.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75656' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
