<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Structured Low-Rank Matrices - Part II of II</h2><div class='index-talk' id='talk134' style='display:block'><a href='javascript:toggle_star(134)' class='star'><span class='star134'>&star;</span></a> <b>11:30 AM&ndash;11:45 AM (G108)</b> Steffen Boerm, Arithmetic Operations with H&#178;-matrices <span id='bitlink-126'><small><a href='javascript:show_bit(126)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-126' style='display:none'><small><a href='javascript:hide_bit(126)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Arithmetic Operations with H&#178;-matrices</b><br />Steffen Boerm<br />Friday, March 3 11:30 AM&ndash;11:45 AM<br />This is the 1st talk in <a href='session-30.html'>Structured Low-Rank Matrices - Part II of II</a> (11:30 AM&ndash;1:10 PM)<br />G108<br /><br /><small>$\mathcal{H}^2$-matrices can be used to represent solution operators both for partial differential and boundary integral equations, but computing these (approximate) representations still presents a challenge, particularly if we want to guarantee a given accuracy.    
This talk presents a technique for approximating the product of two $\mathcal{H}^2$-matrices efficiently. The cluster bases used for compressing the result are computed adaptively in order to guarantee a prescribed accuracy of the approximated matrix.    
Using the efficient matrix multiplication algorithm, more complex tasks like computing the inverse or constructing triangular factorizations can be approached.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75246' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk135' style='display:block'><a href='javascript:toggle_star(135)' class='star'><span class='star135'>&star;</span></a> <b>11:50 AM&ndash;12:05 AM (G108)</b> Matthieu Gerest, Reducing Communications and Memory Costs of Parallel Block Low-Rank Solvers <span id='bitlink-127'><small><a href='javascript:show_bit(127)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-127' style='display:none'><small><a href='javascript:hide_bit(127)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Reducing Communications and Memory Costs of Parallel Block Low-Rank Solvers</b><br />Matthieu Gerest<br />Friday, March 3 11:50 AM&ndash;12:05 AM<br />This is the 2nd talk in <a href='session-30.html'>Structured Low-Rank Matrices - Part II of II</a> (11:30 AM&ndash;1:10 PM)<br />G108<br /><br /><small>Block Low-Rank (BLR) compression is successful at reducing the high computational cost and memory footprint of sparse direct linear solvers. With the growing sizes of problems and increasing relative costs of data movements on modern architectures, it has become crucial to further optimize the memory and communication costs of parallel BLR solvers.   In order to do so, we introduce several new approaches targeting both the LU factorization and solution phases of the solver. The key ideas include using mixed precision representations, designing data access patterns better suited to BLR, and compressing intermediate data, even at the cost of increasing the number of operations. We evaluate the potential of these approaches on a range of matrices coming from real-life problems in industrial and academic applications.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75246' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk136' style='display:block'><a href='javascript:toggle_star(136)' class='star'><span class='star136'>&star;</span></a> <b>12:10 AM&ndash;12:25 AM (G108)</b> George M. Turkiyyah, Distributed Multi-GPU algorithms for H2 Matrices <span id='bitlink-128'><small><a href='javascript:show_bit(128)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-128' style='display:none'><small><a href='javascript:hide_bit(128)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Distributed Multi-GPU algorithms for H2 Matrices</b><br />George M. Turkiyyah<br />Friday, March 3 12:10 AM&ndash;12:25 AM<br />This is the 3rd talk in <a href='session-30.html'>Structured Low-Rank Matrices - Part II of II</a> (11:30 AM&ndash;1:10 PM)<br />G108<br /><br /><small>We describe high-performance, distributed-memory, and GPU-accelerated algorithms for matrix-vector multiplication and matrix recompression of hierarchical matrices in the $\mathcal{H}^2$ format. Results show near-ideal scalability up to 1024 NVIDIA V100 GPUs, with performance exceeding 2.3 Tflop/s/GPU for the matrix-vector multiplication, and 670 Gflops/s/GPU for matrix compression, which involves batched QR and SVD operations. The algorithms are a new module of H2Opus, a performance-oriented package that supports a broad variety of $\mathcal{H}^2$ matrix operations on CPUs and GPUs.    
  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75246' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk137' style='display:block'><a href='javascript:toggle_star(137)' class='star'><span class='star137'>&star;</span></a> <b>12:30 AM&ndash;12:45 AM (G108)</b> Qiangxian Ma, O(N) Factorization of Dense Matrices on GPUs Without Trailing Submatrix Dependencies <span id='bitlink-129'><small><a href='javascript:show_bit(129)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-129' style='display:none'><small><a href='javascript:hide_bit(129)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>O(N) Factorization of Dense Matrices on GPUs Without Trailing Submatrix Dependencies</b><br />Qiangxian Ma<br />Friday, March 3 12:30 AM&ndash;12:45 AM<br />This is the 4th talk in <a href='session-30.html'>Structured Low-Rank Matrices - Part II of II</a> (11:30 AM&ndash;1:10 PM)<br />G108<br /><br /><small>In the previous work, we demonstrated pre-computing the fill-ins and integrate them into the shared basis, allows us to remove the dependency on trailing-matrices even for $\mathcal{H}^2$-matrices. Comparisons with a block low-rank factorization code LORAPO already showed a maximum speed up of 4,700x for a 3-D problem with complex geometry.    
In this talk, we are aiming to give a performance extension of our previous work using batched LAPACK/BLAS API as well as GPUs. The adoption of a method that is free of data dependencies, has great potential of utilizing parallel computing hardware with optimal efficiency.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75246' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
