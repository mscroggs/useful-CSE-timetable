<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Optimal Experimental Design and Robust Optimization for Large-Scale Inverse Problems - Part II of II</h2><div class='index-talk' id='talk96' style='display:block'><a href='javascript:toggle_star(96)' class='star'><span class='star96'>&star;</span></a> <b>2:15 PM&ndash;2:30 PM (D407)</b> Dariusz Uci&#324;ski, Maximin-Efficient Experimental Design for Orthogonally Invariant Information Criteria <span id='bitlink-91'><small><a href='javascript:show_bit(91)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-91' style='display:none'><small><a href='javascript:hide_bit(91)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Maximin-Efficient Experimental Design for Orthogonally Invariant Information Criteria</b><br />Dariusz Uci&#324;ski<br />Tuesday, February 28 2:15 PM&ndash;2:30 PM<br />This is the 1st talk in <a href='session-21.html'>Optimal Experimental Design and Robust Optimization for Large-Scale Inverse Problems - Part II of II</a> (2:15 PM&ndash;3:55 PM)<br />D407<br /><br /><small>Optimal selection of measurement locations for parameter estimation is usually focused on maximizing an optimality criterion defined on the Fisher information matrix (FIM) associated with the estimated parameters. But different optimality criteria may yield different optimal designs. In consequence, strong interest is generated by compromise solutions which would produce decent values for a broadest possible class of design criteria. In the search for such universally suboptimal solutions, an approach is proposed to compute designs maximizing the minimal efficiency with respect to the class of orthogonally invariant information criteria. This class is broad enough to include all optimum design criteria encountered in practice. It turns out that the minimal efficiency with respect to this class equals that with respect to a finite set of criteria which generalize the well-known E-optimum design criterion. An extremely simple and fast algorithm is proposed to numerically construct such designs, which is based on the appropriate semi-infinite programming problem formulation. Its idea is to alternate between solving the eigenproblem for the current FIM and finding a solution to a linear-programming problem. In this way the nondifferentiability of the optimality criterion is circumvented and the algorithm is guaranteed to converge in a finite number of steps.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75225' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk97' style='display:block'><a href='javascript:toggle_star(97)' class='star'><span class='star97'>&star;</span></a> <b>2:35 PM&ndash;2:50 PM (D407)</b> Peng Chen, Fast and Scalable Algorithms for Bayesian Optimal Experimental Design <span id='bitlink-92'><small><a href='javascript:show_bit(92)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-92' style='display:none'><small><a href='javascript:hide_bit(92)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Fast and Scalable Algorithms for Bayesian Optimal Experimental Design</b><br />Peng Chen<br />Tuesday, February 28 2:35 PM&ndash;2:50 PM<br />This is the 2nd talk in <a href='session-21.html'>Optimal Experimental Design and Robust Optimization for Large-Scale Inverse Problems - Part II of II</a> (2:15 PM&ndash;3:55 PM)<br />D407<br /><br /><small>Bayesian optimal experimental design (OED) is a principled framework for maximizing information gained from limited data in Bayesian inverse problems. Unfortunately, conventional methods for OED are prohibitive when applied to expensive models with high-dimensional parameters. In this talk, I will present fast and scalable computational methods for large-scale Bayesian OED with infinite-dimensional parameters, including data-informed low-rank approximation, efficient offline-online decomposition, projected neural network approximation, and a new swapping greedy algorithm for combinatorial optimization.    
  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75225' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk98' style='display:block'><a href='javascript:toggle_star(98)' class='star'><span class='star98'>&star;</span></a> <b>2:55 PM&ndash;3:10 PM (D407)</b> Sarah Feldmann, Source Detection on Graphs <span id='bitlink-93'><small><a href='javascript:show_bit(93)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-93' style='display:none'><small><a href='javascript:hide_bit(93)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Source Detection on Graphs</b><br />Sarah Feldmann<br />Tuesday, February 28 2:55 PM&ndash;3:10 PM<br />This is the 3rd talk in <a href='session-21.html'>Optimal Experimental Design and Robust Optimization for Large-Scale Inverse Problems - Part II of II</a> (2:15 PM&ndash;3:55 PM)<br />D407<br /><br /><small>The source detection problem consists of a weighted connected graph and a signal spreading through it with the following properties. The signal is sent with a constant velocity from a unique unknown source node. For each node there is the possibility to measure the time at which the signal reaches the node. The goal is to find the source node with as few measurements as possible without knowledge of the starting time or the velocity of the signal. This talk takes two cases into account.    
In the deterministic offline case the combinatorial concept of the spread dimension is introduced. Assuming exact computation and no measurement errors, the objective is to determine as few as possible measurement nodes to uniquely locate the source node, no matter which node actually turns out to be the source.    
In the stochastic online case it is discussed how to find a probable source with an iterative algorithm using parameter estimation and experimental design. This iterative approach requires a repetitive nature of the signal so that in each iteration the information gained in the previous iterations can be used.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75225' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk99' style='display:block'><a href='javascript:toggle_star(99)' class='star'><span class='star99'>&star;</span></a> <b>3:15 PM&ndash;3:30 PM (D407)</b> Deepanshu Verma, Advances and Challenges in Solving High-Dimensional HJB Equations Arising in Optimal Control <span id='bitlink-94'><small><a href='javascript:show_bit(94)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-94' style='display:none'><small><a href='javascript:hide_bit(94)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Advances and Challenges in Solving High-Dimensional HJB Equations Arising in Optimal Control</b><br />Deepanshu Verma<br />Tuesday, February 28 3:15 PM&ndash;3:30 PM<br />This is the 4th talk in <a href='session-21.html'>Optimal Experimental Design and Robust Optimization for Large-Scale Inverse Problems - Part II of II</a> (2:15 PM&ndash;3:55 PM)<br />D407<br /><br /><small>This talk presents recent advances in neural network approaches for approximating the value function of high-dimensional control problems. A core challenge of the training process is that the value function estimate and the relevant parts of the state space (those likely to be visited by optimal policies) need to be discovered. We show how insights from optimal control theory can be leveraged to achieve these goals.  To focus the sampling on relevant states during neural network training, we use the Pontryagin maximum principle (PMP) to obtain the optimal controls for the current value function estimate. Our approaches can handle both stochastic and deterministic control problems. Our training loss consists of a weighted sum of the objective functional of the control problem and penalty terms that enforce the HJB equations along the sampled trajectories.  Importantly, training is self-supervised, in that, it does not require solutions of the control problem.      We will present several numerical experiments for deterministic and stochastic problems with state dimensions of about 100 and compare our methods to existing approaches.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75225' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
