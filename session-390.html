<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Variational Models for Machine Learning</h2><div class='index-talk' id='talk1772' style='display:block'><a href='javascript:toggle_star(1772)' class='star'><span class='star1772'>&star;</span></a> <b>4:00 PM&ndash;4:15 PM (D402)</b> Jalal Fadili, Continuum Limit of the Eikonal Equation on Graphs <span id='bitlink-1619'><small><a href='javascript:show_bit(1619)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1619' style='display:none'><small><a href='javascript:hide_bit(1619)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Continuum Limit of the Eikonal Equation on Graphs</b><br />Jalal Fadili<br />Wednesday, March 1 4:00 PM&ndash;4:15 PM<br />This is the 1st talk in <a href='session-390.html'>Variational Models for Machine Learning</a> (4:00 PM&ndash;5:40 PM)<br />D402<br /><br /><small>In this work, we study a graph approximation of the time-dependent (local) Eikonal equation with Dirichlet-type boundary conditions, where the kernel in the non-local problem is properly scaled. Based on the theory of viscosity solutions, we prove existence and uniqueness of the viscosity solutions of both the local and non-local problems, as well as regularity properties of these solutions in time and space. We then derive error bounds between the solution to the graph problem and its continuum limit both in continuous-time (gradient flow) and Euler time discretization. In particular, we establish that if the kernel scale parameter decreases at an appropriate rate as n grows, then almost surely, the solution of the problem on graphs converges uniformly to the viscosity solution of the local problem as the time step vanishes and the number vertices n grows large.   </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75864' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1773' style='display:block'><a href='javascript:toggle_star(1773)' class='star'><span class='star1773'>&star;</span></a> <b>4:20 PM&ndash;4:35 PM (D402)</b> Anastasiia Hraivoronska, A Variational Approach to Discrete-to-Continuum Convergence of Evolutionary Equations with Gradient Structure <span id='bitlink-1620'><small><a href='javascript:show_bit(1620)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1620' style='display:none'><small><a href='javascript:hide_bit(1620)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>A Variational Approach to Discrete-to-Continuum Convergence of Evolutionary Equations with Gradient Structure</b><br />Anastasiia Hraivoronska<br />Wednesday, March 1 4:20 PM&ndash;4:35 PM<br />This is the 2nd talk in <a href='session-390.html'>Variational Models for Machine Learning</a> (4:00 PM&ndash;5:40 PM)<br />D402<br /><br /><small> </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75864' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1774' style='display:block'><a href='javascript:toggle_star(1774)' class='star'><span class='star1774'>&star;</span></a> <b>4:40 PM&ndash;4:55 PM (D402)</b> Marcello Carioni, Sparsity for Variational Problems and Applications to Infinitely Wide Shallow Neural Networks <span id='bitlink-1621'><small><a href='javascript:show_bit(1621)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1621' style='display:none'><small><a href='javascript:hide_bit(1621)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Sparsity for Variational Problems and Applications to Infinitely Wide Shallow Neural Networks</b><br />Marcello Carioni<br />Wednesday, March 1 4:40 PM&ndash;4:55 PM<br />This is the 3rd talk in <a href='session-390.html'>Variational Models for Machine Learning</a> (4:00 PM&ndash;5:40 PM)<br />D402<br /><br /><small> </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75864' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1775' style='display:block'><a href='javascript:toggle_star(1775)' class='star'><span class='star1775'>&star;</span></a> <b>5:00 PM&ndash;5:15 PM (D402)</b> Wonjun Lee, Monotone Discretizations of Levelset Convex Geometric PDEs <span id='bitlink-1622'><small><a href='javascript:show_bit(1622)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1622' style='display:none'><small><a href='javascript:hide_bit(1622)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Monotone Discretizations of Levelset Convex Geometric PDEs</b><br />Wonjun Lee<br />Wednesday, March 1 5:00 PM&ndash;5:15 PM<br />This is the 4th talk in <a href='session-390.html'>Variational Models for Machine Learning</a> (4:00 PM&ndash;5:40 PM)<br />D402<br /><br /><small>We present a new algorithm that converges to level set convex viscosity solutions of high-dimensional Hamiton-Jacobi equations. The algorithm can be used to solve a wide class of curvature motion PDEs, as well as a recent Hamilton-Jacobi equation for the Tukey depth, which is a statistical depth measure of data points. The algorithm is based on monotone schemes that involve partial derivatives in directions orthogonal to the gradient. We provide the convergence analysis of the algorithm on regular Cartesian grids and unstructured point clouds in any dimensions, and numerical experiments that demonstrate approximated solutions of affine flows in 2D and Tukey depth measure of high dimensional data, such as MNIST and FashionMNIST datasets.    
    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75864' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1776' style='display:block'><a href='javascript:toggle_star(1776)' class='star'><span class='star1776'>&star;</span></a> <b>5:20 PM&ndash;5:35 PM (D402)</b> Chengyang Huang, Inverse Reinforcement Learning via Variantioanl System Identification of Fokker-Planck Equation <span id='bitlink-1623'><small><a href='javascript:show_bit(1623)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1623' style='display:none'><small><a href='javascript:hide_bit(1623)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Inverse Reinforcement Learning via Variantioanl System Identification of Fokker-Planck Equation</b><br />Chengyang Huang<br />Wednesday, March 1 5:20 PM&ndash;5:35 PM<br />This is the 5th talk in <a href='session-390.html'>Variational Models for Machine Learning</a> (4:00 PM&ndash;5:40 PM)<br />D402<br /><br /><small>Inverse Reinforcement Learning (IRL) is an inverse problem of Reinforcement Learning (RL) that uncovers the reward function of a Markov decision process from observed trajectories of an agent. It is an appealing way to quantify the rationale behind the behavior of humans or any living agents. Like other inverse problems, IRL is ill-posed and becomes especially challenging when the transition model is unknown or inaccessible for sampling because the evolution of states and actions depends both on the transition model and the agent's policy, which is derived from the transition model as well together with the reward function. Current IRL approaches either assume the transition model is accessible or utilize data-driven methods to estimate the transition model beforehand without considering physics. We propose a novel physics-aware IRL algorithm that can simultaneously infer the reward function and transition probability function. We first build a connection between the value function in RL and the potential function in the Fokker-Planck equation and then employ a variational system identification method to infer the potential function. The reward function and transition probability function can then be evaluated instantaneously with the built connection. We demonstrate our new approach using a Gridworld benchmark problem and a biological problem of cancer cells.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75864' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
