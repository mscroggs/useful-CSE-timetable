<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Information Fusion for Computational Models and Inverse Problems - Part I of II</h2><div class='index-talk' id='talk482' style='display:block'><a href='javascript:toggle_star(482)' class='star'><span class='star482'>&star;</span></a> <b>9:45 AM&ndash;10:00 AM (E105)</b> Tian Yu Yen, Measuring Uncertainty in Data Fusion Algorithms <span id='bitlink-446'><small><a href='javascript:show_bit(446)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-446' style='display:none'><small><a href='javascript:hide_bit(446)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Measuring Uncertainty in Data Fusion Algorithms</b><br />Tian Yu Yen<br />Wednesday, March 1 9:45 AM&ndash;10:00 AM<br />This is the 1st talk in <a href='session-107.html'>Information Fusion for Computational Models and Inverse Problems - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E105<br /><br /><small>In recent years, the fields of optimization, uncertainty quantification and machine learning have all been gravitating towards developing algorithms and models that can enable the capacity to incorporate, or fuse, data from disparate sources or fidelities. In this talk, we give an overview of common themes in approaches for data fusion across applications and domains, setting the stage for subsequent discussions and talks in this minisymposia. In addition, we discuss current challenges in information fusion and discuss our recent work developing methods of uncertainty quantification for data fusion algorithms.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75381' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk483' style='display:block'><a href='javascript:toggle_star(483)' class='star'><span class='star483'>&star;</span></a> <b>10:05 AM&ndash;10:20 AM (E105)</b> Luis Espath, Physics-Informed Spectral Learning: Stability and Convergence <span id='bitlink-447'><small><a href='javascript:show_bit(447)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-447' style='display:none'><small><a href='javascript:hide_bit(447)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Physics-Informed Spectral Learning: Stability and Convergence</b><br />Luis Espath<br />Wednesday, March 1 10:05 AM&ndash;10:20 AM<br />This is the 2nd talk in <a href='session-107.html'>Information Fusion for Computational Models and Inverse Problems - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E105<br /><br /><small> </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75381' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk484' style='display:block'><a href='javascript:toggle_star(484)' class='star'><span class='star484'>&star;</span></a> <b>10:25 AM&ndash;10:40 AM (E105)</b> Madalina Fiterau, Progressive Fusion for Multimodal Integration <span id='bitlink-448'><small><a href='javascript:show_bit(448)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-448' style='display:none'><small><a href='javascript:hide_bit(448)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Progressive Fusion for Multimodal Integration</b><br />Madalina Fiterau<br />Wednesday, March 1 10:25 AM&ndash;10:40 AM<br />This is the 3rd talk in <a href='session-107.html'>Information Fusion for Computational Models and Inverse Problems - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E105<br /><br /><small>Integration of multimodal information from various sources has been shown to boost the performance of machine learning models and thus has received increased attention in recent years. Often such models use deep modality-specific networks to obtain unimodal features which are combined to obtain `late-fusion' representations. However, these designs run the risk of information loss in the respective unimodal pipelines. On the other hand, `early-fusion' methodologies, which combine features early, suffer from the problems associated with feature heterogeneity and high sample complexity.     
We present an iterative representation refinement approach, called Progressive Fusion, which mitigates the issues with late fusion representations. Our model-agnostic technique introduces backward connections that make late stage fused representations available to early layers, improving the expressiveness of the representations at those stages, while retaining the advantages of late fusion designs. We test Progressive Fusion on tasks including affective sentiment detection, multimedia analysis, and time series fusion with different models, demonstrating its versatility. We show that our approach consistently improves performance, for instance attaining a 5% reduction in MSE and 40% improvement in robustness on multimodal time series prediction.    
    
  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75381' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk485' style='display:block'><a href='javascript:toggle_star(485)' class='star'><span class='star485'>&star;</span></a> <b>10:45 AM&ndash;11:00 AM (E105)</b> Mohammad Motamed, Residual Multi-Fidelity Neural Networks <span id='bitlink-449'><small><a href='javascript:show_bit(449)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-449' style='display:none'><small><a href='javascript:hide_bit(449)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Residual Multi-Fidelity Neural Networks</b><br />Mohammad Motamed<br />Wednesday, March 1 10:45 AM&ndash;11:00 AM<br />This is the 4th talk in <a href='session-107.html'>Information Fusion for Computational Models and Inverse Problems - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E105<br /><br /><small>We present a residual multi-fidelity computational framework that effectively utilizes the approximation power of deep neural networks. Given a low-fidelity and a high-fidelity computational model, we formulate the correlation between the two models in terms of a residual function. Precisely, instead of searching for a direct correlation between the two models, we consider a possibly nonlinear relation between the low-fidelity model and the residual of the two models. The smaller magnitude of the residual function, compared to the size of the high-fidelity quantity, enables the construction of a residual network that learns the residual function using a small set of high-fidelity data. The trained residual network is then used to efficiently generate additional high-fidelity data. Finally, the set of all available and newly generated high-fidelity data are used to train a deep network that learns the high-fidelity quantity of interest. We present several numerical examples to demonstrate the power of the proposed framework. We show that dramatic savings in computational cost may be achieved when the output predictions are desired to be accurate within small tolerances.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75381' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk486' style='display:block'><a href='javascript:toggle_star(486)' class='star'><span class='star486'>&star;</span></a> <b>11:05 AM&ndash;11:20 AM (E105)</b> Jiawen Wei, Neural-Network Interpretability for Time Series Classification Task <span id='bitlink-450'><small><a href='javascript:show_bit(450)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-450' style='display:none'><small><a href='javascript:hide_bit(450)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Neural-Network Interpretability for Time Series Classification Task</b><br />Jiawen Wei<br />Wednesday, March 1 11:05 AM&ndash;11:20 AM<br />This is the 5th talk in <a href='session-107.html'>Information Fusion for Computational Models and Inverse Problems - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E105<br /><br /><small>Neural networks (NN) have been gaining significant traction for time series classification tasks over the past few years. Yet, they are frequently perceived as black-box tools, whose results may be difficult to interpret. To address this issue, several methods have been proposed to obtain maps of relevance scores highlighting the importance of different time steps for a given model. These methods were initially applied to images, and more recently to time-series data. Yet, interpretability of NN remains challenging. Trust in these interpretability methods will only be brought through a formal evaluation of their performance, which has been studied but with some drawbacks. These methods typically provide different evaluations of importance, sometimes even diametrically opposite results, and do not explain how neurons collaborate to represent specific patterns. Some studies, therefore, aim to introduce novel metrics to rank interpretability methods across the most commonly used machine learning (ML) models. Another aspect of the research focuses on developing novel interpretability methods to provide more meaningful insights for practitioners working with ML models. In this work, we extend interpretability methods to recognize patterns indicative of a given class across samples. We argue that this work is a critical step toward understanding NN-based decisions for a given classification task at a more holistic dataset scale, rather than the individual sample.  	  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75381' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
