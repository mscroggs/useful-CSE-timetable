<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Co-Design for Heterogeneous System Architectures - Part II of II</h2><div class='index-talk' id='talk327' style='display:block'><a href='javascript:toggle_star(327)' class='star'><span class='star327'>&star;</span></a> <b>2:15 PM&ndash;2:30 PM (E102)</b> George Markomanolis, Hardware, Software, and Application Co-Design on the Frontier and Lumi Systems <span id='bitlink-300'><small><a href='javascript:show_bit(300)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-300' style='display:none'><small><a href='javascript:hide_bit(300)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Hardware, Software, and Application Co-Design on the Frontier and Lumi Systems</b><br />George Markomanolis<br />Tuesday, February 28 2:15 PM&ndash;2:30 PM<br />This is the 1st talk in <a href='session-72.html'>Co-Design for Heterogeneous System Architectures - Part II of II</a> (2:15 PM&ndash;3:55 PM)<br />E102<br /><br /><small>The first Exascale systems are based on heterogeneous node designs. These systems are intended to run a range of applications across a wide set of domains scientific and machine learning applications. Ensuring these applications can leverage all the unique architectural features of the heterogeneous node design requires deep application co-design between hardware, software, and application teams. This talk discusses some of the challenges, and solutions, on preparing applications for the AMD-based OLCF Frontier and CSC LUMI-G systems. This talk will highlight key hardware capabilities, such as matrix cores, packed Fused-multiply-add operations, large HBM capacities, coherent CPU and GPU memory, and how to leverage them in software. Supporting applications on multiple architectures via performance portable compilers such as OpenMP and HIP will also be discussed.     </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75319' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk328' style='display:block'><a href='javascript:toggle_star(328)' class='star'><span class='star328'>&star;</span></a> <b>2:35 PM&ndash;2:50 PM (E102)</b> Mario Krell, Application and System Co-Design for Extreme Scale AI Workloads <span id='bitlink-301'><small><a href='javascript:show_bit(301)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-301' style='display:none'><small><a href='javascript:hide_bit(301)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Application and System Co-Design for Extreme Scale AI Workloads</b><br />Mario Krell<br />Tuesday, February 28 2:35 PM&ndash;2:50 PM<br />This is the 2nd talk in <a href='session-72.html'>Co-Design for Heterogeneous System Architectures - Part II of II</a> (2:15 PM&ndash;3:55 PM)<br />E102<br /><br /><small>The true potential of AI rests on super-human learning capacity, and on the ability to selectively draw on that learning. Both properties---scale and selectivity---challenge the design of AI computers and the tools used to program them. This talk will discuss these challenges, and how Graphcore, a company that builds accelerators for AI, has been and will be breaking through them by co-designing new applications, software and hardware infrastructures to achieve super-human learning.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75319' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk329' style='display:block'><a href='javascript:toggle_star(329)' class='star'><span class='star329'>&star;</span></a> <b>2:55 PM&ndash;3:10 PM (E102)</b> Martin Mueller, Machine Learning Assisted Simulation Using Highly Coupled GPU, CPU and Deep Learning Accelerators <span id='bitlink-302'><small><a href='javascript:show_bit(302)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-302' style='display:none'><small><a href='javascript:hide_bit(302)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Machine Learning Assisted Simulation Using Highly Coupled GPU, CPU and Deep Learning Accelerators</b><br />Martin Mueller<br />Tuesday, February 28 2:55 PM&ndash;3:10 PM<br />This is the 3rd talk in <a href='session-72.html'>Co-Design for Heterogeneous System Architectures - Part II of II</a> (2:15 PM&ndash;3:55 PM)<br />E102<br /><br /><small>High performance computing workloads have started to leverage the benefits of AI both in software and hardware, namely merging traditional, first principles workloads with deep learning models. In multiphysics problems, intersection of machine learning with first principles simulation, sometimes referred to as cognitive simulation, has given rise to new paradigms in computational modeling and simulation where benefits are yet to be recognized.   In this talk, we will focus on a specific subclass of ML assisted simulation, where tens, hundreds or potentially thousands of surrogate models representing different physiochemical phenomena, material properties, and regimes, are used to replace sections of the computational code historically solved through first principles methods. The simulation will run on innovative node-level heterogeneous design, consisting of Reconfigurable Dataflow Unit (RDU), GPU, and CPU. We will show for cases where strong coupling between the surrogate models and the main computational loop is required (i.e., calling the surrogates within a computational loop for each step of the simulation), and for problems that are latency-bound with low number of inference calls to each model (i.e., small batch sizes) SambaNova’s Reconfigurable Dataflow Architecture (RDA) serves particularly well. An example use case will be presented and the improvements will be discussed.     </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75319' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk331' style='display:block'><a href='javascript:toggle_star(331)' class='star'><span class='star331'>&star;</span></a> <b>3:15 PM&ndash;3:30 PM (E102)</b> Jan Verschelde, Newton's Method to Compute Taylor Series in Multiple Double Precision Accelerated by Graphics Processing Units <span id='bitlink-303'><small><a href='javascript:show_bit(303)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-303' style='display:none'><small><a href='javascript:hide_bit(303)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Newton's Method to Compute Taylor Series in Multiple Double Precision Accelerated by Graphics Processing Units</b><br />Jan Verschelde<br />Tuesday, February 28 3:15 PM&ndash;3:30 PM<br />This is the 4th talk in <a href='session-72.html'>Co-Design for Heterogeneous System Architectures - Part II of II</a> (2:15 PM&ndash;3:55 PM)<br />E102<br /><br /><small>The problem is to investigate the scalability of a new path tracker  (SISC 42(6), A3610-A3637, 2020) to solve systems of polynomial equations  in many variables.  The many in this context is about a thousand.  Path trackers repeatedly run Newton's method, evaluating and differentiating  polynomials, followed by the solution of a linear system.  On Taylor series,  the matrices are block Toeplitz lower triangular, obtained by convolutions.    
Proximity to singularities requires multiple double precision arithmetic,  which causes a cost overhead to be offset by acceleration with Graphics  Processing Units (GPUs).  In particular, GPUs capable of teraflop  performance compensate for the overhead caused by quad double arithmetic.  Multiple double precision is necessary to adjust the parameter representation  in case the radius of convergence of the Taylor series is too small.    
Singularities are located efficiently via the quadratically converging  Newton's method at regular points and with extrapolation on the series.  While the current implementation takes polynomials on input, viewing   polynomials as truncated series extends its application to analytic systems,  systems of functions with well defined Taylor series developments.    
The software written for this investigation is licensed under GPL-3.0,  available at https://github.com/janverschelde/PHCpack.    
This research is supported by the U.S. National Science Foundation   under grant 1854513 of the CDS&E-MSS program.    
  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75319' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
