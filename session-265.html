<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Bridging Numerical Analysis and Machine Learning - Part II of II</h2><div class='index-talk' id='talk1205' style='display:block'><a href='javascript:toggle_star(1205)' class='star'><span class='star1205'>&star;</span></a> <b>1:50 PM&ndash;2:05 PM (D402)</b> Konstantinos Ritos, Physics Informed Neural Networks Assessment on Fluid Dynamics Problems <span id='bitlink-1116'><small><a href='javascript:show_bit(1116)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1116' style='display:none'><small><a href='javascript:hide_bit(1116)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Physics Informed Neural Networks Assessment on Fluid Dynamics Problems</b><br />Konstantinos Ritos<br />Wednesday, March 1 1:50 PM&ndash;2:05 PM<br />This is the 1st talk in <a href='session-265.html'>Bridging Numerical Analysis and Machine Learning - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />D402<br /><br /><small>Machine learning and more specifically deep learning have revolutionised the way classification, pattern recognition, and regression tasks are performed in various application areas. Historically the solving of computational fluid dynamics problems relies on finite elements and finite volume methods, meaning complex meshes and an important number of degrees of freedom are used to estimate solutions to governing equations. Recently however the development of the Physics Informed Neural Network (PINN) has emerged as a promising tool to improve the solution methods to these equations. The purpose of this talk is to assess different variants of these methods on a few representative equations from fluid dynamics. We aim to show how the performance and the precision of different types of models are affected by altering networks hyper-parameters including altering number of hidden layers, number of neurons to a hidden layers and the use of different activation functions including locally adaptive functions which have been shown to improve the accuracy of estimators. We will propose then some alternatives to the state of the art.    
  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75605' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1206' style='display:block'><a href='javascript:toggle_star(1206)' class='star'><span class='star1206'>&star;</span></a> <b>2:10 PM&ndash;2:25 PM (D402)</b> Syver Agdenstein, Learning Filtered Discretisation Operators: Non-Intrusive vs Intrusive Approaches <span id='bitlink-1117'><small><a href='javascript:show_bit(1117)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1117' style='display:none'><small><a href='javascript:hide_bit(1117)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Learning Filtered Discretisation Operators: Non-Intrusive vs Intrusive Approaches</b><br />Syver Agdenstein<br />Wednesday, March 1 2:10 PM&ndash;2:25 PM<br />This is the 2nd talk in <a href='session-265.html'>Bridging Numerical Analysis and Machine Learning - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />D402<br /><br /><small>Simulating multi-scale phenomena such as turbulent fluid flows is typically computationally very expensive. Filtering the smaller scales allows for using coarse discretizations, however, this requires closure models to account for the effects of the unresolved on the resolved scales. The common approach is to filter the continuous equations, but this gives rise to several commutator errors due to nonlinear terms, non-uniform filters, or boundary conditions. We propose a new approach to filtering, where the equations are discretized  first and then filtered. For a non-uniform filter applied to the linear convection equation, we show that the discretely filtered convection operator can be inferred using three methods: intrusive (‘explicit reconstruction’) or non-intrusive operator inference, either via ‘derivative fitting’ or ‘trajectory fitting’ (embedded learning). We show that explicit reconstruction and derivative fitting identify a similar operator and produce small errors, but that trajectory fitting requires signicant effort to train to achieve similar performance. However, the explicit reconstruction approach is more prone to instabilities.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75605' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1207' style='display:block'><a href='javascript:toggle_star(1207)' class='star'><span class='star1207'>&star;</span></a> <b>2:30 PM&ndash;2:45 PM (D402)</b> Rahul Dhopeshwar, Non-Intrusive Model Order Reduction for Nonlinear Coupled Problems <span id='bitlink-1118'><small><a href='javascript:show_bit(1118)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1118' style='display:none'><small><a href='javascript:hide_bit(1118)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Non-Intrusive Model Order Reduction for Nonlinear Coupled Problems</b><br />Rahul Dhopeshwar<br />Wednesday, March 1 2:30 PM&ndash;2:45 PM<br />This is the 3rd talk in <a href='session-265.html'>Bridging Numerical Analysis and Machine Learning - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />D402<br /><br /><small>We are interested in thermo-electro-mechanical problems arising in applications like curing process and spark plasma sintering. These models consists of non-linear material models like viscoelasticity and viscoplasticity. High-fidelity simulations of such coupled multiphysics problems are prohibitively expensive for performing parametric studies, optimization, control or estimation. In order to solve such problems, accelerating the forward model solves by means of efficient reduced order models is necessary. However, developing ROMs addressing these non-linearities is challenging due to the history dependence and presence of internal variables.    
To address this, hyper-reduction techniques have been used in the literature to construct reduced order models for non-linear problems. In particular, Reduced Basis - Empirical Quadrature Procedure (RB-EQP) has been used for hyperelasticity problems. RB-EQP has been shown to provide offline efficiency by reducing the number of integration points and the required full-order solves which can be very expensive to compute. Furthermore, methods in scientific machine learning have demonstrated online efficiency by avoiding expensive assembly of the reduced nonlinear problem. Exploiting these advantages of hyper-reduction and ML methods, we propose a unified numerical framework for an offline and online efficient non-intrusive ROM technique. Finally, we demonstrate the performance of the proposed method on a macroscale sintering problem.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75605' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1208' style='display:block'><a href='javascript:toggle_star(1208)' class='star'><span class='star1208'>&star;</span></a> <b>2:50 PM&ndash;3:05 PM (D402)</b> Tim Roith, A Bregman Learning Framework for Sparse Neural Networks <span id='bitlink-1119'><small><a href='javascript:show_bit(1119)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1119' style='display:none'><small><a href='javascript:hide_bit(1119)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>A Bregman Learning Framework for Sparse Neural Networks</b><br />Tim Roith<br />Wednesday, March 1 2:50 PM&ndash;3:05 PM<br />This is the 4th talk in <a href='session-265.html'>Bridging Numerical Analysis and Machine Learning - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />D402<br /><br /><small>I will present a novel learning framework based on stochastic Bregman iterations. It allows to train sparse neural networks with an inverse scale space approach, starting from a very sparse network and gradually adding significant parameters. Apart from a baseline algorithm called LinBreg, I will also speak about an accelerated version using momentum, and AdaBreg, which is a Bregmanized generalization of the Adam algorithm. I will present a statistically profound sparse parameter initialization strategy, stochastic convergence analysis of the loss decay, and additional convergence proofs in the convex regime. The Bregman learning framework can also be applied to Neural Architecture Search and can, for instance, unveil autoencoder architectures for denoising or deblurring tasks.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75605' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1209' style='display:block'><a href='javascript:toggle_star(1209)' class='star'><span class='star1209'>&star;</span></a> <b>3:10 PM&ndash;3:25 PM (D402)</b> Joerg Fehr, Model Enhancement by Discovering Friction Terms Using Physics-Informed Neural Networks for Control <span id='bitlink-1120'><small><a href='javascript:show_bit(1120)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1120' style='display:none'><small><a href='javascript:hide_bit(1120)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Model Enhancement by Discovering Friction Terms Using Physics-Informed Neural Networks for Control</b><br />Joerg Fehr<br />Wednesday, March 1 3:10 PM&ndash;3:25 PM<br />This is the 5th talk in <a href='session-265.html'>Bridging Numerical Analysis and Machine Learning - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />D402<br /><br /><small>Often, technical systems cannot be fully modeled due to limited knowledge, limited resources or due to the complexity of the task to be solved. This leads to shortcomings in the resulting governing equations and to a lack of accuracy. In a control setting, this is often treated by a larger control input.  However, modern physics-inspired machine learning does not only allow us to solve complex problems in a data-driven way, but also to gain new insights into the underlying physics. In this work, we use physics-informed neural networks (PINNs) as well as sparse regression learning to identify the missing physics of a complex system inside a control setting. In detail, we identify nonlinear friction terms inside the model of a 2-dof manipulator based on a limited number of training data, which is either obtained from simulation or experiment. Based on the original and enhanced model, we generate feed-forward control sequences for a trajectory tracking task. A simple PID controller is used to compensate for errors that occur in the feed-forward control. The results show that the controller has to make far fewer corrections to the control variable based on the improved model than was the case with the original model.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75605' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
