<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Performance Engineering and Applications - Part II of II</h2><div class='index-talk' id='talk467' style='display:block'><a href='javascript:toggle_star(467)' class='star'><span class='star467'>&star;</span></a> <b>1:50 PM&ndash;2:05 PM (D404)</b> Herbert Owen, An Optimal GPU Implementation for Computational Fluid Dynamics with the Finite Element Code Alya <span id='bitlink-431'><small><a href='javascript:show_bit(431)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-431' style='display:none'><small><a href='javascript:hide_bit(431)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>An Optimal GPU Implementation for Computational Fluid Dynamics with the Finite Element Code Alya</b><br />Herbert Owen<br />Wednesday, March 1 1:50 PM&ndash;2:05 PM<br />This is the 1st talk in <a href='session-104.html'>Performance Engineering and Applications - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />D404<br /><br /><small>Alya is a high-performance computational mechanics code for complex coupled multiphysics engineering problems. It is one of the two CFD codes of the Unified European Applications Benchmark Suite (UEBAS). On its path to Exascale, it has needed significant changes to adapt to new architectures, such as GPUs. This work describes recent improvements focused on large-scale incompressible flow problems. The momentum equation is treated explicitly while the pressure is solved implicitly. A fractional step scheme is used to enable elements that do not satisfy the inf-sup condition. The Laplacian matrix for the pressure remains fixed during the simulation for typical cases with a fixed mesh. Therefore, the two main kernels are calculating the right-hand side term for the momentum equation and the solution of a linear system for the pressure. This work focuses on the first step, but some minor comments on the linear solver will also be presented.   Compared to our previous GPU implementation,  more than an order of magnitude reduction in computational time for the assembly has been obtained. OpenACC has allowed us to be close to 50% of the maximum floating-point performance on an A100 Nvidia GPU. While optimizing the GPU version, improvements to the CPU implementation have also been obtained. Comparing the current CPU and GPU energy consumption shows good agreement with the ratios one can expect from the Top500 or Green500 lists.     
  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75375' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk468' style='display:block'><a href='javascript:toggle_star(468)' class='star'><span class='star468'>&star;</span></a> <b>2:10 PM&ndash;2:25 PM (D404)</b> Moritz T. Hof, Exploiting Tensor Product Structure to Accelerate Eigenvalue Problem Solvers in Few-Body Physics <span id='bitlink-432'><small><a href='javascript:show_bit(432)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-432' style='display:none'><small><a href='javascript:hide_bit(432)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Exploiting Tensor Product Structure to Accelerate Eigenvalue Problem Solvers in Few-Body Physics</b><br />Moritz T. Hof<br />Wednesday, March 1 2:10 PM&ndash;2:25 PM<br />This is the 2nd talk in <a href='session-104.html'>Performance Engineering and Applications - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />D404<br /><br /><small>In this presentation a computationally and numerically efficient method to compute both binding energies and their corresponding wave function in quantum mechanical few-body physics.   The linear eigenvalue solver takes exploits the tensor product structure of the multidimensional stationary Schr√∂dinger equation. The application of the Hamiltonian Operator is represented by matrix-matrix methods and then combined with a newly-designed preconditioner for the Jacobi-Davidson QR. This tensor method allows for significantly faster, highly-accurate computation of the three-body energies. For higher dimensions, we introduced a hybrid distributed/shared memory parallel approach. A GPU accelerated computing implementation was also considered. We will analyses the advantages of this implementation by looking at throughput, latency, memory usage as well as the numerical performance considerations        </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75375' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk469' style='display:block'><a href='javascript:toggle_star(469)' class='star'><span class='star469'>&star;</span></a> <b>2:30 PM&ndash;2:45 PM (D404)</b> Christie Louis Alappat, Accelerating Sparse Iterative Solvers and Preconditioners Using Race <span id='bitlink-433'><small><a href='javascript:show_bit(433)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-433' style='display:none'><small><a href='javascript:hide_bit(433)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Accelerating Sparse Iterative Solvers and Preconditioners Using Race</b><br />Christie Louis Alappat<br />Wednesday, March 1 2:30 PM&ndash;2:45 PM<br />This is the 3rd talk in <a href='session-104.html'>Performance Engineering and Applications - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />D404<br /><br /><small>Sparse linear iterative solvers are indispensable for large-scale simulations. In this talk, we present methods to accelerate some of the existing solvers and preconditioners by using the concept of levels as developed in the context of our RACE library framework. Levels are constructed using breadth-first search on the graph related to the underlying sparse matrix. These levels are then used to implement cache blocking of the matrix elements for high spatial and temporal reuse. The approach finds its use in kernels like sparse-matrix-power vector multiplication, which perform back-to-back sparse-matrix vector multiplication (SpMV)-type iterations without global synchronizations in between. The method is highly effective and achieves performance levels of 50-100 GF/s on a single modern Intel or AMD multicore chip, providing speedups of typically 2x - 4x compared to a highly optimized classical SpMV implementation.    
After briefly introducing the optimization strategy, we shed light on the application of these optimized kernels in iterative solvers. To this end, we discuss the coupling of the RACE library with the Trilinos framework and address the application to communication-avoiding s-step Krylov solvers, polynomial preconditioners, and algebraic multigrid preconditioners. We then dive into the performance benefits and challenges of the RACE integration and show that our optimization produces numerically identical results and improves the total solver time by 1.3x - 2x.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75375' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk470' style='display:block'><a href='javascript:toggle_star(470)' class='star'><span class='star470'>&star;</span></a> <b>2:50 PM&ndash;3:05 PM (D404)</b> Robert J. Harrison, Performance Engineering of Madness <span id='bitlink-434'><small><a href='javascript:show_bit(434)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-434' style='display:none'><small><a href='javascript:hide_bit(434)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Performance Engineering of Madness</b><br />Robert J. Harrison<br />Wednesday, March 1 2:50 PM&ndash;3:05 PM<br />This is the 4th talk in <a href='session-104.html'>Performance Engineering and Applications - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />D404<br /><br /><small>MADNESS (multiresolution numerical environment for scientific simulation) is a long-lived community software project that employs multiresolution analysis (MRA) and an advanced parallel runtime to solve differential and integral equations in broad areas of physics and chemistry with guarantees of both accuracy and speed.  Its irregular and fine grain computational patterns have proven challenging to port to modern hybrid computer architectures.  In this presentation, we discuss experience porting and tuning the software to the Fujitsu A64FX processor and also the complete re-design and new implementation using the Template Task Graph programming model in order to exploit GPUs and the massive size of modern exascale supercomputers.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75375' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk471' style='display:block'><a href='javascript:toggle_star(471)' class='star'><span class='star471'>&star;</span></a> <b>3:10 PM&ndash;3:25 PM (D404)</b> Chris N. Richardson, Effective Simd Vectorisation for Finite Element Kernels <span id='bitlink-435'><small><a href='javascript:show_bit(435)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-435' style='display:none'><small><a href='javascript:hide_bit(435)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Effective Simd Vectorisation for Finite Element Kernels</b><br />Chris N. Richardson<br />Wednesday, March 1 3:10 PM&ndash;3:25 PM<br />This is the 5th talk in <a href='session-104.html'>Performance Engineering and Applications - Part II of II</a> (1:50 PM&ndash;3:30 PM)<br />D404<br /><br /><small>We examine the performance of finite element kernels for a wide range of problems on different CPU architectures. When the code is structured appropriately, modern compilers can auto-vectorize very effectively, and almost ideal vectorization can be achieved. As an added benefit, the maintenance and portability burden of special intrinsics and special programming instructions can be avoided.     The structure of the code may also need to vary depending on the machine architecture. In general, memory bandwidth is a more important factor than raw floating-point performance. A performance model is presented, based on empirical data such as cache bandwidths and flops, to guide the optimization process and algorithm selection.      Finally, automatic code generation is used to write suitable code for different kernels, whilst incorporating the insights from the performance model and compiler-friendly code design.     We present the node-level performance of our generated code for three different architectures: Intel Icelake, Fujitsu A64fx, and AMD Milan processors.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75375' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
