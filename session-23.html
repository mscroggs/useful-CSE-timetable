<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Bayesian Optimization in the Real World - Part II of II</h2><div class='index-talk' id='talk104' style='display:block'><a href='javascript:toggle_star(104)' class='star'><span class='star104'>&star;</span></a> <b>4:45 PM&ndash;5:00 PM (G102)</b> David Bindel, Global Stochastic Optimization of Stellarator Coils <span id='bitlink-99'><small><a href='javascript:show_bit(99)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-99' style='display:none'><small><a href='javascript:hide_bit(99)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Global Stochastic Optimization of Stellarator Coils</b><br />David Bindel<br />Thursday, March 2 4:45 PM&ndash;5:00 PM<br />This is the 1st talk in <a href='session-23.html'>Bayesian Optimization in the Real World - Part II of II</a> (4:45 PM&ndash;6:25 PM)<br />G102<br /><br /><small>In the construction of a stellarator, the manufacturing and assembling of the coil system is a dominant cost. These coils need to satisfy strict engineering tolerances, and if those are not met the project could be canceled as in the case of the National Compact Stellarator Experiment (NCSX) project. Therefore, our goal is to find coil configurations that increase construction tolerances without compromising the performance of the magnetic field. In this paper, we develop a gradient-based stochastic optimization model which seeks robust stellarator coil configurations in high dimensions. In particular, we design a two-step method: first, we perform an approximate global search by a sample efficient trust-region Bayesian optimization; second, we refine the minima found in step one with a stochastic local optimizer. To this end, we introduce two stochastic local optimizers: BFGS applied to the Sample Average Approximation and Adam, equipped with a control variate for variance reduction. Numerical experiments performed on a W7-X-like coil configuration demonstrate that our global optimization approach finds a variety of promising local solutions at less than 0.1% of the cost of previous work, which considered solely local stochastic optimization.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75229' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk105' style='display:block'><a href='javascript:toggle_star(105)' class='star'><span class='star105'>&star;</span></a> <b>5:05 PM&ndash;5:20 PM (G102)</b> Aaron Klein, Bayesian Optimization for Hyperparameter and Neural Architecture Search <span id='bitlink-100'><small><a href='javascript:show_bit(100)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-100' style='display:none'><small><a href='javascript:hide_bit(100)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Bayesian Optimization for Hyperparameter and Neural Architecture Search</b><br />Aaron Klein<br />Thursday, March 2 5:05 PM&ndash;5:20 PM<br />This is the 2nd talk in <a href='session-23.html'>Bayesian Optimization in the Real World - Part II of II</a> (4:45 PM&ndash;6:25 PM)<br />G102<br /><br /><small>Hyperparameter and neural architecture search (HNAS) has been arguable one of the biggest success stories of Bayesian optimization. This is manifested in a long list of well-known open-source frameworks and commercial services that provide Bayesian optimization solutions for HNAS problems.  However, despite its success, vanilla Bayesian optimization faces several challenges on popular HNAS use-cases: First, Bayesian optimization itself needs to become more robust and automated, to not open another hyperparameter optimization problem on top. Second, with the ever increasing computational demands of machine learning, we have to accelerate the optimization process as much as possible. Third, there is a growing interest to optimize more than just the validation performance, such as inference latency or model size.  In this talk, I will present an overview of our recent work that tries to overcome the current short-coming of Bayesian optimization. I argue that these are necessary steps towards fully automated machine learning systems that are able to learn truly end-to-end.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75229' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk106' style='display:block'><a href='javascript:toggle_star(106)' class='star'><span class='star106'>&star;</span></a> <b>5:25 PM&ndash;5:40 PM (G102)</b> Natalie T. Maus, Latent Space Bayesian Optimization for Molecular Design <span id='bitlink-101'><small><a href='javascript:show_bit(101)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-101' style='display:none'><small><a href='javascript:hide_bit(101)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Latent Space Bayesian Optimization for Molecular Design</b><br />Natalie T. Maus<br />Thursday, March 2 5:25 PM&ndash;5:40 PM<br />This is the 3rd talk in <a href='session-23.html'>Bayesian Optimization in the Real World - Part II of II</a> (4:45 PM&ndash;6:25 PM)<br />G102<br /><br /><small>Computational drug discovery can often be cast as a black-box optimization problem, where we aim to design a molecule of interest which maximizes some black-box objective function (i.e. its binding affinity to some target protein). However, optimization over molecules is challenging since the objective function is defined over the discrete and structured space of all possible molecules. Latent space Bayesian optimization (LS-BO) has recently emerged as a promising approach for optimizing over such search spaces. In LS-BO, a deep autoencoder model (DAE) maps molecules into a continuous latent space where familiar Bayesian optimization tools can be more readily applied. While recent work in this area has made rapid progress on the design of better DAEs for this task, relatively little attention has been paid to the optimization component. This is problematic, as the DAEs used typically have high dimensional latent spaces, which significantly degrades the performance of traditional Bayesian optimization algorithms. To address this issue, we develop a novel method to adapt recent work on high-dimensional Bayesian optimization to the LS-BO setting. Our method achieves as much as 20x improvement over state-of-the-art methods across five molecular design tasks.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75229' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk107' style='display:block'><a href='javascript:toggle_star(107)' class='star'><span class='star107'>&star;</span></a> <b>5:45 PM&ndash;6:00 PM (G102)</b> David Eriksson, High-Dimensional Multi-Objective Bayesian Optimization for Optical Design <span id='bitlink-102'><small><a href='javascript:show_bit(102)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-102' style='display:none'><small><a href='javascript:hide_bit(102)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>High-Dimensional Multi-Objective Bayesian Optimization for Optical Design</b><br />David Eriksson<br />Thursday, March 2 5:45 PM&ndash;6:00 PM<br />This is the 4th talk in <a href='session-23.html'>Bayesian Optimization in the Real World - Part II of II</a> (4:45 PM&ndash;6:25 PM)<br />G102<br /><br /><small>The ability to optimize multiple competing objective functions with high sample efficiency is imperative in many applied problems across science and industry. Multi-objective Bayesian optimization (BO) achieves strong empirical performance on such problems, but even with recent methodological advances, it has been restricted to simple, low-dimensional domains. Most existing BO methods exhibit poor performance on search spaces with more than a few dozen parameters. In this work we propose MORBO, a method for multi-objective Bayesian optimization over high-dimensional search spaces. MORBO performs local Bayesian optimization within multiple trust regions simultaneously, allowing it to explore and identify diverse solutions even when the objective functions are difficult to model globally. We show that MORBO significantly advances the state-of-the-art in sample-efficiency for several high-dimensional synthetic and real-world multi-objective problems, including a vehicle design problem with 222 parameters, demonstrating that MORBO is a practical approach for challenging and important problems that were previously out of reach for BO methods.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75229' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
