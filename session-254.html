<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Blending Learning and Dynamical Systems - Part I of II</h2><div class='index-talk' id='talk1156' style='display:block'><a href='javascript:toggle_star(1156)' class='star'><span class='star1156'>&star;</span></a> <b>9:45 AM&ndash;10:00 AM (E106)</b> Daniel Sanz-Alonso, Auto-Differentiable Ensemble Kalman Filters <span id='bitlink-1069'><small><a href='javascript:show_bit(1069)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1069' style='display:none'><small><a href='javascript:hide_bit(1069)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Auto-Differentiable Ensemble Kalman Filters</b><br />Daniel Sanz-Alonso<br />Tuesday, February 28 9:45 AM&ndash;10:00 AM<br />This is the 1st talk in <a href='session-254.html'>Blending Learning and Dynamical Systems - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E106<br /><br /><small>Data assimilation is concerned with sequentially estimating a temporally-evolving state. This task, which arises in a wide range of scientific and engineering applications, is particularly challenging when the state is high-dimensional and the state-space dynamics are unknown. In this talk I will introduce a machine learning framework for learning dynamical systems in data assimilation. Our auto-differentiable ensemble Kalman filters (AD-EnKFs) blend ensemble Kalman filters for state recovery with machine learning tools for learning the dynamics. In doing so, AD-EnKFs leverage the ability of ensemble Kalman filters to scale to high-dimensional states and the power of automatic differentiation to train high-dimensional surrogate models for the dynamics. Numerical results using the Lorenz-96 model show that AD-EnKFs outperform existing methods that use expectation-maximization or particle filters to merge data assimilation and machine learning. In addition, AD-EnKFs are easy to implement and require minimal tuning.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75580' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1157' style='display:block'><a href='javascript:toggle_star(1157)' class='star'><span class='star1157'>&star;</span></a> <b>10:05 AM&ndash;10:20 AM (E106)</b> Zhen Zhang, Structure Preserving Neural Networks for Identifying and Solving Dynamical Systems <span id='bitlink-1070'><small><a href='javascript:show_bit(1070)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1070' style='display:none'><small><a href='javascript:hide_bit(1070)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Structure Preserving Neural Networks for Identifying and Solving Dynamical Systems</b><br />Zhen Zhang<br />Tuesday, February 28 10:05 AM&ndash;10:20 AM<br />This is the 2nd talk in <a href='session-254.html'>Blending Learning and Dynamical Systems - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E106<br /><br /><small>We propose the symplectic neural network (SympNet) that are composed of unit lower/upper triangular matrix-like maps for solving and identifying conservative dynamical systems from data. We theoretically proved that SympNets are universal approximators within the class of symplectic maps. We apply SympNet to learn the evolution map from the molecular dynamics (MD) simulation results across multiple steps, which reduces the computational cost of traditional MD solver by 20% on GPU while being able to keeping energy constant in the NVE ensemble. We apply SympNet to solve the high dimensional path planning problems. We experimentally showed that our neural-network-based method SympNets can overcome the curse of dimensionality by solving the path planning problem of 256 closely interacted drones in 1.5 hours.    
As a generalization of SympNet, we proposed the GENERIC formalism informed neural network (GFINN), which exactly satisfies the first and second law of thermodynamics, to facilitate prediction of the evolution of complex processes that are dissipative in nature. The architecture is inspired by the spectral decomposition of skew-symmetric and positive definite matrices. Based on rigorous approximation theory, we prove that our model approximates any system that can be described by the GENERIC formalism in a thermodynamics-consistent way. We apply GFINN to predict the motion of thermoelastic double-pendulum governed by Gough-Joule effect.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75580' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1158' style='display:block'><a href='javascript:toggle_star(1158)' class='star'><span class='star1158'>&star;</span></a> <b>10:25 AM&ndash;10:40 AM (E106)</b> Louis Sharrock, Parameter Estimation for the McKean-Vlasov Stochastic Differential Equation <span id='bitlink-1071'><small><a href='javascript:show_bit(1071)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1071' style='display:none'><small><a href='javascript:hide_bit(1071)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Parameter Estimation for the McKean-Vlasov Stochastic Differential Equation</b><br />Louis Sharrock<br />Tuesday, February 28 10:25 AM&ndash;10:40 AM<br />This is the 3rd talk in <a href='session-254.html'>Blending Learning and Dynamical Systems - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E106<br /><br /><small>McKean-Vlasov SDEs arise naturally in many applications as the mean field limit of systems of interacting particles. They are important in many fields, from mathematical biology (e.g., neuroscience and population dynamics) to the social sciences (e.g., opinion dynamics and cooperative behaviours), to high-dimensional Bayesian inference. In this talk, we will discuss online parameter estimation for a McKean-Vlasov SDE and the associated system of weakly interacting particles. We propose a new online estimator, which evolves according to a continuous-time stochastic gradient descent algorithm on the asymptotic log-likelihood of the interacting particle system. We obtain various convergence results for this estimator, under assumptions which guarantee ergodicity and uniform-in-time propagation chaos. Our theoretical results are supported via several numerical examples, including a toy linear mean field model, a stochastic Kuramoto model, and a stochastic opinion dynamics model.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75580' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1159' style='display:block'><a href='javascript:toggle_star(1159)' class='star'><span class='star1159'>&star;</span></a> <b>10:45 AM&ndash;11:00 AM (E106)</b> Matthieu Darcy, One Shot Learning of Stochastic Differential Equations with Gaussian Processes <span id='bitlink-1072'><small><a href='javascript:show_bit(1072)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1072' style='display:none'><small><a href='javascript:hide_bit(1072)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>One Shot Learning of Stochastic Differential Equations with Gaussian Processes</b><br />Matthieu Darcy<br />Tuesday, February 28 10:45 AM&ndash;11:00 AM<br />This is the 4th talk in <a href='session-254.html'>Blending Learning and Dynamical Systems - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E106<br /><br /><small>We consider the problem of learning the drift and diffusion functions of a Stochastic Differential Equation of the form $ dX_t = f(X_t)dt+\sigma(X_t)dW_t $ from one sample trajectory. This problem is challenging because one sample trajectory only provides indirect information on the unknown functions $f$, $\sigma$, and stochastic process $dW_t$ representing the drift, the diffusion, and the stochastic forcing terms, respectively. In this talk we present a simple kernel-based solution that decomposes the problem as follows:  1) Express the increments of the SDE as a computational graph.  2) Recover the unknown functions through a Maximum a Posteriori Estimation (MAP) estimator with Gaussian Process (GP) priors.  3) Optimize the kernels of the GPs using randomized cross validation.  We illustrate the efficacy, robustness, and scope of our method through numerical examples.    
Co-authors: Boumediene Hamzi, Giulia Livieri, Houman Owhadi,Peyman Tavallali.    
    
  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75580' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1160' style='display:block'><a href='javascript:toggle_star(1160)' class='star'><span class='star1160'>&star;</span></a> <b>11:05 AM&ndash;11:20 AM (E106)</b> David Ebert, On Uncertainty Quantification of Eigenpairs with Higher Multiplicity <span id='bitlink-1073'><small><a href='javascript:show_bit(1073)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-1073' style='display:none'><small><a href='javascript:hide_bit(1073)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>On Uncertainty Quantification of Eigenpairs with Higher Multiplicity</b><br />David Ebert<br />Tuesday, February 28 11:05 AM&ndash;11:20 AM<br />This is the 5th talk in <a href='session-254.html'>Blending Learning and Dynamical Systems - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E106<br /><br /><small>We consider generalized variational eigenvalue problems with random perturbations in the bilinear forms.   This setting is motivated by Galerkin discretizations of the Helmholtz equation or Maxwell's equations with random material laws, for example.   The considered eigenpairs can be of higher but finite multiplicity.   We investigate stochastic quantities of interest of the eigenspaces and discuss why, for multiplicity greater than 1, only the stochastic properties of the eigenspaces are meaningful, but not of individual eigenpairs.   To that end, we characterize the Fréchet derivatives of the eigenpairs with respect to the perturbation and provide a new linear characterization for eigenpairs of higher multiplicity.   Based on the Fréchet derivatives of the eigenpair we discuss a meaningful sampling strategy for multiple eigenvalues and develop an uncertainty quantification perturbation approach.   In the latter, the arising tensor equations for the covariance can be efficiently solved by a low-rank method, although alternate approaches such as sparse grids are also feasible.   Finally, we discuss performance gains compared to sampling based methods.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75580' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
