<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Traditional OED and Beyond - Part I of II</h2><div class='index-talk' id='talk1058' style='display:block'><a href='javascript:toggle_star(1058)' class='star'><span class='star1058'>&star;</span></a> <b>2:35 PM&ndash;2:50 PM (G105)</b> John D. Jakeman, Risk-Averse Goal-Oriented Optimal Experimental Design Using Nonlinear Models <span id='bitlink-974'><small><a href='javascript:show_bit(974)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-974' style='display:none'><small><a href='javascript:hide_bit(974)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Risk-Averse Goal-Oriented Optimal Experimental Design Using Nonlinear Models</b><br />John D. Jakeman<br />Thursday, March 2 2:35 PM&ndash;2:50 PM<br />This is the 1st talk in <a href='session-232.html'>Traditional OED and Beyond - Part I of II</a> (2:35 PM&ndash;4:15 PM)<br />G105<br /><br /><small>Traditionally, nonlinear Bayesian optimal experimental design (OED) uses numerical models to predict when and where to collect data to minimize uncertainty in model parameters. This talk will present novel goal-oriented nonlinear Bayesian OED strategies that minimize uncertainty in predictions. Our risk averse strategies can be used to produce designs that most inform tail statistics in a scalar or vector valued quantity of interest. In the latter situation a specialized case of our general framework provides a nonlinear interpolation between I and G optimality which minimize average and worst case variance respectively. We will demonstrate the utility of our OED strategies for placing sensors that minimize uncertainty in predictions of an advection diffusion model.    
  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75554' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1059' style='display:block'><a href='javascript:toggle_star(1059)' class='star'><span class='star1059'>&star;</span></a> <b>2:55 PM&ndash;3:10 PM (G105)</b> Tobin Isaac, Robust Expected Information Gain in Optimal Experimental Design <span id='bitlink-975'><small><a href='javascript:show_bit(975)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-975' style='display:none'><small><a href='javascript:hide_bit(975)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Robust Expected Information Gain in Optimal Experimental Design</b><br />Tobin Isaac<br />Thursday, March 2 2:55 PM&ndash;3:10 PM<br />This is the 2nd talk in <a href='session-232.html'>Traditional OED and Beyond - Part I of II</a> (2:35 PM&ndash;4:15 PM)<br />G105<br /><br /><small>Expected information gain (EIG) is a useful measure of experiment optimality, but it can rarely be computed exactly, and there are drawbacks associated with different approximations.  Nested Monte Carlo and related methods are popular approaches to estimating EIG.  We note two issues with the use of these estimators.  The first is the effect that outliers can have in the estimators when they are undersampled.  The second is the sensitivity of experiments to perturbations in the prior: the sensitivity of an experiment's EIG to perturbations in the prior should affect its suitability in a risk averse situation.  We propose a quantity called robust expected information gain (REIG) that maximizes the minimum EIG over perturbations in the prior which maps onto a fast post-processing of Monte Carlo estimators, which in some cases can also address the outlier affect.  We show numerical experiments comparing REIG estimators to EIG estimators on simple problems, then on an OED problem modeling experiments with catalysis reactors to determine kinematic reaction coefficients.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75554' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1060' style='display:block'><a href='javascript:toggle_star(1060)' class='star'><span class='star1060'>&star;</span></a> <b>3:15 PM&ndash;3:30 PM (G105)</b> Jake Callahan, Bayesian OED for Sensor Placement: Analysis and Optimization of Seismo-Acoustic Monitoring Networks with Bayesian Optimal Experimental Design <span id='bitlink-976'><small><a href='javascript:show_bit(976)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-976' style='display:none'><small><a href='javascript:hide_bit(976)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Bayesian OED for Sensor Placement: Analysis and Optimization of Seismo-Acoustic Monitoring Networks with Bayesian Optimal Experimental Design</b><br />Jake Callahan<br />Thursday, March 2 3:15 PM&ndash;3:30 PM<br />This is the 3rd talk in <a href='session-232.html'>Traditional OED and Beyond - Part I of II</a> (2:35 PM&ndash;4:15 PM)<br />G105<br /><br /><small>Bayesian optimal experimental design (OED) seeks to identify data, sensor configurations, or experiments which can optimally reduce uncertainty. OED formulates the choice of experiment as an optimization problem that maximizes the expected information gain (EIG) about quantities of interest given prior knowledge and models of expected observation data.     
We use Bayesian OED to find optimal sensor configurations for detecting seismic events as part of a seismic monitoring network. We configure sensor networks by choosing sensor locations, types, and fidelity in order to improve our ability to identify and locate seismic sources.  In this work, we develop the framework necessary to use Bayesian OED to optimize a sensor network's ability to locate seismic events from arrival time data of detected seismic phases. As part of this framework we introduce methods for performing importance sampling on difficult prior distributions and methods for placing unusual constraints on our optimization domain to account for real world limits on sensor location.     
Once we have developed this framework, we can explore many relevant questions to monitoring such as how to trade off sensor fidelity and earth model uncertainty, how choice of prior distribution and domain restrictions affect sensor placement, and how sensor types, number, and locations influence uncertainty.       
    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75554' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1061' style='display:block'><a href='javascript:toggle_star(1061)' class='star'><span class='star1061'>&star;</span></a> <b>3:35 PM&ndash;3:50 PM (G105)</b> Ruanui Nicholson, Bayesian Optimal Experimental Design in the Presence of Model Uncertainty <span id='bitlink-977'><small><a href='javascript:show_bit(977)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-977' style='display:none'><small><a href='javascript:hide_bit(977)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Bayesian Optimal Experimental Design in the Presence of Model Uncertainty</b><br />Ruanui Nicholson<br />Thursday, March 2 3:35 PM&ndash;3:50 PM<br />This is the 4th talk in <a href='session-232.html'>Traditional OED and Beyond - Part I of II</a> (2:35 PM&ndash;4:15 PM)<br />G105<br /><br /><small>We consider optimal experimental design (OED) of nonlinear inverse problems in the Bayesian framework. The problem is further complicated by considering a set up in which the governing equations contain further auxiliary parameters which are also unknown, but are assumed to be of little interest.  To account for the additional model uncertainty in the governing equations we employ the so-called Bayesian approximation error (BAE) approach. We show that failure to take into account the additional model uncertainty at the OED stage relates in a sub-optimal design, while failure to take into account at the inference stage relates in significant over confidence in heavily biased estimates, i.e., an infeasible posterior. In this talk, we consider the optimal design of infinite-dimensional nonlinear Bayesian inverse problems. We derive a marginalised A-optimality criterion and develop an efficient computational approach to solve the associated optimisation problem. We demonstrate the applicability of our approach by considering the estimation of a Robin coefficient for the Poisson problem when the (unknown) internal conductivity is treated as an auxiliary parameter.    
    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75554' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk1062' style='display:block'><a href='javascript:toggle_star(1062)' class='star'><span class='star1062'>&star;</span></a> <b>3:55 PM&ndash;4:10 PM (G105)</b> Serge Prudhomme, Optimal Design of Validation Experiments Using Sensitivity Indices <span id='bitlink-978'><small><a href='javascript:show_bit(978)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-978' style='display:none'><small><a href='javascript:hide_bit(978)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Optimal Design of Validation Experiments Using Sensitivity Indices</b><br />Serge Prudhomme<br />Thursday, March 2 3:55 PM&ndash;4:10 PM<br />This is the 5th talk in <a href='session-232.html'>Traditional OED and Beyond - Part I of II</a> (2:35 PM&ndash;4:15 PM)<br />G105<br /><br /><small>The main objective of using physical models is the prediction of quantities of interest (QoIs) under specific regimes called prediction scenarios. These QoIs are usually not observable, as they may refer to future predictions or predictions in conditions that cannot be reproduced in a laboratory. This raises the fundamental issue of validating a model with respect to these QoIs. Several validation processes and metrics have been proposed to assert whether a model is deemed valid. However, they rarely take into account the QoIs, essentially for the reasons mentioned above. One has then to make a leap of faith to use the model, validated w.r.t. given observables, for predicting other QoIs. Our goal is nevertheless to gain confidence in the predictive capabilities of the model by defining validation experiments specifically designed toward this objective. We propose here a methodology to design a validation scenario that relates the QoIs in the prediction scenario with the observables in the validation scenario. It consists in casting the design of the validation scenario as an optimal design problem. We introduce here an optimal design problem whose objective functional minimizes the difference between sensitivity indices (e.g. Sobol indices) of the QoIs in the prediction scenario and those related with the same QoIs in the validation scenario. We will demonstrate the usefulness of our methodology on several examples by showing that it can identify false positives.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75554' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
