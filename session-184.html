<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Scientific Machine Learning to Enable Outer Loop Analysis - Part I of II</h2><div class='index-talk' id='talk841' style='display:block'><a href='javascript:toggle_star(841)' class='star'><span class='star841'>&star;</span></a> <b>9:45 AM&ndash;10:00 AM (E104)</b> Sahil Bhola, Information-Theoretic Approaches for Model Identifiability in Inverse Problems <span id='bitlink-775'><small><a href='javascript:show_bit(775)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-775' style='display:none'><small><a href='javascript:hide_bit(775)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Information-Theoretic Approaches for Model Identifiability in Inverse Problems</b><br />Sahil Bhola<br />Monday, February 27 9:45 AM&ndash;10:00 AM<br />This is the 1st talk in <a href='session-184.html'>Scientific Machine Learning to Enable Outer Loop Analysis - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E104<br /><br /><small>An information-theoretic estimator is proposed to assess the global identifiability of statistical models in a practical setting. No assumptions are made on the structure of the statistical model or the prior distribution while constructing the estimator. The estimator has the following notable advantages: first, no controlled experiment or data is required to conduct the practical identifiability analysis; second, different forms of uncertainties, such as model-form, parameter, or measurement can be taken into account; third, the identifiability analysis is global, rather than being restricted to a local region of the parameter space. If an individual parameter is unidentifiable, it can belong to an identifiable subset such that parameters within the subset have a functional relationship with one another and thus have a combined effect on the statistical model.  The practical identifiability framework is extended to highlight the dependencies between parameter pairs that emerge a posteriori, with the goal of finding identifiable parameter subsets.  The applicability of the proposed approach is demonstrated using a linear Gaussian model and a non-linear methane-air reduced kinetics model.    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75486' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk842' style='display:block'><a href='javascript:toggle_star(842)' class='star'><span class='star842'>&star;</span></a> <b>10:05 AM&ndash;10:20 AM (E104)</b> Elizabeth Newman, Automating Hyperparameter Tuning for Deep Neural Network Training <span id='bitlink-776'><small><a href='javascript:show_bit(776)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-776' style='display:none'><small><a href='javascript:hide_bit(776)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Automating Hyperparameter Tuning for Deep Neural Network Training</b><br />Elizabeth Newman<br />Monday, February 27 10:05 AM&ndash;10:20 AM<br />This is the 2nd talk in <a href='session-184.html'>Scientific Machine Learning to Enable Outer Loop Analysis - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E104<br /><br /><small>Deep neural networks (DNN) have become central to scientific machine learning (SciML) due to their ability to approximate a wide range of functions and thereby act as surrogate models.  Despite their success and prevalence, DNNs are notoriously difficult to train.  In this talk, we will address the DNN training challenge of choosing hyperparameters, such as the learning rate and regularization parameter, which often are chosen by trial-and-error.  Our approach will automate the choice of hyperparameters during training using iterative sampling techniques.  We will demonstrate the efficacy of our approach on various tasks vital to SciML, including surrogate modeling and dimensionality reduction.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75486' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk843' style='display:block'><a href='javascript:toggle_star(843)' class='star'><span class='star843'>&star;</span></a> <b>10:25 AM&ndash;10:40 AM (E104)</b> Jules Berman, Low-Dimensional Models with Nonlinear Parametrizations for Systems of Transport-Dominated Evolution Equations <span id='bitlink-777'><small><a href='javascript:show_bit(777)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-777' style='display:none'><small><a href='javascript:hide_bit(777)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Low-Dimensional Models with Nonlinear Parametrizations for Systems of Transport-Dominated Evolution Equations</b><br />Jules Berman<br />Monday, February 27 10:25 AM&ndash;10:40 AM<br />This is the 3rd talk in <a href='session-184.html'>Scientific Machine Learning to Enable Outer Loop Analysis - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E104<br /><br /><small>Latent dynamics of transport-dominated evolution phenomena such as described by hyperbolic conservation laws typically exhibit nonlinear structures that make traditional linear dimensionality reduction methods in low-dimensional subspaces inefficient. In this presentation, we build on Dirac-Frenkel variational methods to propagate forward in time nonlinear parametrizations such as deep neural networks that efficiently describe the latent dynamics of transport-dominated problems. The key contribution is an extension of previous work to handle systems of equations. Each variable, e.g., pressure and velocity, is described by a separate nonlinear parameterization, which are subsequently coupled together. Numerical results demonstrate that the proposed approach requires few degrees of freedom to accurately describe and predict transport-dominated dynamics.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75486' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk844' style='display:block'><a href='javascript:toggle_star(844)' class='star'><span class='star844'>&star;</span></a> <b>10:45 AM&ndash;11:00 AM (E104)</b> Arnau Alb&#224;, Lasso Monte Carlo, a Novel Method for High Dimensional Uncertainty Quantification <span id='bitlink-778'><small><a href='javascript:show_bit(778)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-778' style='display:none'><small><a href='javascript:hide_bit(778)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Lasso Monte Carlo, a Novel Method for High Dimensional Uncertainty Quantification</b><br />Arnau Alb&#224;<br />Monday, February 27 10:45 AM&ndash;11:00 AM<br />This is the 4th talk in <a href='session-184.html'>Scientific Machine Learning to Enable Outer Loop Analysis - Part I of II</a> (9:45 AM&ndash;11:25 AM)<br />E104<br /><br /><small>High-dimensional uncertainty quantification (UQ) is an active area of research, applicable to virtually all domains of science and engineering. In particular in the field of nuclear engineering, simulation codes use nuclear data libraries with tens of thousands of uncertain values, that need to be propagated to the output of the simulations. The most common methods used for UQ are Monte Carlo and surrogate-modelling. The former method is dimensionality independent but has a slow convergence, while the latter method has been shown to yield large computational speedups with respect to Monte Carlo. However, surrogate models are biased and suffer from the curse of dimensionality, becoming costly to train for high-dimensional problems. We present a new technique, Lasso Monte Carlo (LMC), which combines surrogate models and the multilevel Monte Carlo technique, to perform UQ in high-dimensional problems. We prove the unbiasedness of LMC, and that it can converge faster than simple Monte Carlo. The method is numerically tested on a variety of problems: high-dimensional linear functions, the Sobol function where LMC is compared to PCE, the FPUT lattice problem, and on a nuclear physics problem of calculations for spent nuclear fuel involving over ten thousand dimensions. The LMC method has faster convergence than simple Monte Carlo in all tests, and reduces the computational cost of UQ by up to a factor of 5.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75486' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
