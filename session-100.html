<html>
<head>
<link rel="apple-touch-icon" sizes="57x57" href="apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<title>Useful CSE timetable</title>
<style type='text/css'>
a.star {text-decoration:none;font-size:150%}
.header-links a {display:inline-block;padding:10px}
.header-links a,.header-links a:link,.header-links a:visited,.header-links a:active {color:blue;text-decoration:none}
.header-links a:hover {color:blue;text-decoration:underline}
</style>
<script type='text/javascript' src='fave.js?v=2023-02-27-02'></script>

</head>
<body>
<div class='header-links'>
<a href='index.html'>Personal timetable</a>
<a href='speakers.html'>List of speakers</a>
<a href='titles.html'>List of talk titles</a>
<a href='sync.html'>Copy favourites to another device</a>
</div>
<div class='header-links'>
<a href='https://meetings.siam.org/program.cfm?CONFCODE=cse23' target='new'><small>Official conference programme</small></a>
<a href='https://raw.githubusercontent.com/mscroggs/useful-CSE-timetable/json/talks.json' target='new'><small>Talks in JSON format</small></a>
<a href='https://github.com/mscroggs/useful-CSE-timetable/' target='new'><small>GitHub</small></a>
</div>
<h1>SIAM CSE 2023</h1>


<h2>Advances at the Intersection of Data Assimilation and Inverse Problems</h2><div class='index-talk' id='talk450' style='display:block'><a href='javascript:toggle_star(450)' class='star'><span class='star450'>&star;</span></a> <b>2:15 PM&ndash;2:30 PM (G101)</b> Femke Vossepoel, On Ensemble Size in a Particle Method for Subsidence Estimation <span id='bitlink-415'><small><a href='javascript:show_bit(415)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-415' style='display:none'><small><a href='javascript:hide_bit(415)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>On Ensemble Size in a Particle Method for Subsidence Estimation</b><br />Femke Vossepoel<br />Tuesday, February 28 2:15 PM&ndash;2:30 PM<br />This is the 1st talk in <a href='session-100.html'>Advances at the Intersection of Data Assimilation and Inverse Problems</a> (2:15 PM&ndash;3:55 PM)<br />G101<br /><br /><small>We use a particle method in two different experiments with models of different complexity.  The first model calculates subsidence for a single observation point due to a single source and considers independent and uncorrelated parameters and observations.  The second model calculates the observed subsidence as a summation of subsidence contributions from multiple sources.  In the latter model, the spatial response that a single subsidence source causes at the surface will result in correlated observations. The correlation in the resulting observations may trigger weight collapse in the particle method.    
The information loss related to the spatial correlation can be quantified with mutual information.  Using the quantification of information loss, we illustrate how this loss of information is reflected in the log-likelihood of the estimation problem, and how this depends on the number of parameters of the model.  Based on the results of these experiments, we propose criteria to evaluate the required ensemble size for the assimilation of spatially correlated subsidence observations.     
    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75371' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk451' style='display:block'><a href='javascript:toggle_star(451)' class='star'><span class='star451'>&star;</span></a> <b>2:35 PM&ndash;2:50 PM (G101)</b> Nisha Chandramoorthy, A Dynamics-Aware Measure Transport Algorithm for Bayesian Filtering in Uniformly Hyperbolic Dynamics <span id='bitlink-416'><small><a href='javascript:show_bit(416)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-416' style='display:none'><small><a href='javascript:hide_bit(416)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>A Dynamics-Aware Measure Transport Algorithm for Bayesian Filtering in Uniformly Hyperbolic Dynamics</b><br />Nisha Chandramoorthy<br />Tuesday, February 28 2:35 PM&ndash;2:50 PM<br />This is the 2nd talk in <a href='session-100.html'>Advances at the Intersection of Data Assimilation and Inverse Problems</a> (2:15 PM&ndash;3:55 PM)<br />G101<br /><br /><small>In Bayesian filtering, we recursively update the probability measures of the state of a dynamical system conditioned on past observations. Numerical methods for the filtering recursion based on Kalman filter variants make the Gaussian assumption, and particle filters are computationally prohibitive in high dimensions. Transport map-based methods are computationally tractable and applicable to non-Gaussian problems but do not make use of the underlying dynamics present in the filtering setting. Our goal is to construct a dynamics-aware computationally tractable algorithm to sample from filtering distributions in uniformly hyperbolic systems (idealized chaotic systems). To this end, we express the filtering recursion by involving the scores (gradients of logarithms) of the filtering distribution sequence and show that these scores can be estimated efficiently by exploiting uniform hyperbolicity. We propose an ansatz for the filtering map: composition of forecast and analysis steps on the phase space. While the filtering map is not, in general, unique, our ansatz allows an interpretation of the filtering map as a conjugacy between two dynamical systems and imposes uniqueness. Such an interpretation along with the score equation constraint gives rise to a novel algorithm to perform filtering via measure transport. This algorithm is derived and demonstrated on low-dimensional hyperbolic dynamics.          </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75371' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk452' style='display:block'><a href='javascript:toggle_star(452)' class='star'><span class='star452'>&star;</span></a> <b>2:55 PM&ndash;3:10 PM (G101)</b> Michela Ottobre, Criteria for Uniform in Time Numerical Approximations of Stochastic Differential Equations <span id='bitlink-417'><small><a href='javascript:show_bit(417)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-417' style='display:none'><small><a href='javascript:hide_bit(417)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Criteria for Uniform in Time Numerical Approximations of Stochastic Differential Equations</b><br />Michela Ottobre<br />Tuesday, February 28 2:55 PM&ndash;3:10 PM<br />This is the 3rd talk in <a href='session-100.html'>Advances at the Intersection of Data Assimilation and Inverse Problems</a> (2:15 PM&ndash;3:55 PM)<br />G101<br /><br /><small>
Complicated models, for which a detailed analysis is too far out of reach, are routinely approximated via a variety of procedures; this is the case when we use multiscale methods, when we take many particle limits and obtained a simplified, coarse-grained dynamics, or, simply, when we use numerical methods. While approximating,  we make an error which is small over small time-intervals but it typically compounds over longer time-horizons. Hence, in general, the approximation error grows in time so that the results of our &#8220;predictions" are less reliable when we look at longer time-horizons.   However this is not necessarily the case and one may be able to find dynamics and corresponding approximation procedures for which the error remains bounded, uniformly in time.  We will discuss a very general approach to understand when this is possible.  I will show how the approach we take is very broad and show how it can be used for all of the approximation procedures mentioned above â€“ with a particular focus on numerical approximations for SDEs. This is based on a series of joint works with L. Angeli, D. Crisan, P. Dobson, I. Souttar.     
  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75371' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk453' style='display:block'><a href='javascript:toggle_star(453)' class='star'><span class='star453'>&star;</span></a> <b>3:15 PM&ndash;3:30 PM (G101)</b> Nazanin Abedini, Convergence Properties for Data Assimilation Based on Gauss-Newton Iteration <span id='bitlink-418'><small><a href='javascript:show_bit(418)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-418' style='display:none'><small><a href='javascript:hide_bit(418)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>Convergence Properties for Data Assimilation Based on Gauss-Newton Iteration</b><br />Nazanin Abedini<br />Tuesday, February 28 3:15 PM&ndash;3:30 PM<br />This is the 4th talk in <a href='session-100.html'>Advances at the Intersection of Data Assimilation and Inverse Problems</a> (2:15 PM&ndash;3:55 PM)<br />G101<br /><br /><small>Data assimilation is the problem of finding a state of a dynamical system such that the difference between true state and an approximated one is small in a properly defined sense. The widely-used data-assimilation methods are variational methods. They aim at finding an optimal initial condition of the dynamical model such that the distance to the observations is minimized. The problem is formulated as a minimization of a nonlinear least-square problem with respect to initial condition, and it is usually solved using a Gauss-Newton method. Motivated by the variational approach, we consider a data-assimilation method that minimizes a cost function under assumption of model error. We are seeking a solution over a time window at once. We prove the method converges to the true state in the case of noise-free observations  and provide error bound in the case of noisy observations. Furthermore, we extend the method to parameter estimation. We confirm our theoretical results with numerical experiments using the Lorenz models.    
    </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75371' target='new'>More information on the conference website</a></small></div></span></div><div class='index-talk' id='talk454' style='display:block'><a href='javascript:toggle_star(454)' class='star'><span class='star454'>&star;</span></a> <b>3:35 PM&ndash;3:50 PM (G101)</b> Andre Marchildon, A Non-Intrusive Solution to the Ill-Conditioned Gaussian Kernel Covariance Matrix for Gradient-Enhanced Gaussian Processes <span id='bitlink-419'><small><a href='javascript:show_bit(419)'>&#x25BC; Show talk info &#x25BC;</a></small></span><span id='bit-419' style='display:none'><small><a href='javascript:hide_bit(419)'>&#x25B2; Hide talk info &#x25B2;</a></small><div style='padding:20px'><b>A Non-Intrusive Solution to the Ill-Conditioned Gaussian Kernel Covariance Matrix for Gradient-Enhanced Gaussian Processes</b><br />Andre Marchildon<br />Tuesday, February 28 3:35 PM&ndash;3:50 PM<br />This is the 5th talk in <a href='session-100.html'>Advances at the Intersection of Data Assimilation and Inverse Problems</a> (2:15 PM&ndash;3:55 PM)<br />G101<br /><br /><small>Gaussian processes (GPs) provide a probabilistic method of constructing surrogates that is used for various applications such as uncertainty quantification and Bayesian optimization. A common problem for GPs is the ill-conditioning of their covariance matrix, particularly when the popular Gaussian kernel is used. For gradient-free GPs, a modest nugget can be added to the diagonal of the covariance matrix to ensure its condition number is below a user-set threshold. Unfortunately, it is problematic to apply this method on its own for gradient-enhanced GPs since it can require a large nugget, which is detrimental to the accuracy of the GP. A novel method has been developed that guarantees that the condition number of the gradient-enhanced Gaussian kernel covariance matrix remains below a user-set threshold. This is achieved by using non-isotropic rescaling for the data and a modest nugget. This method is straightforward to implement, non-intrusive, applicable to problems of any dimension, and it allows all data to be kept. To demonstrate the effectiveness of this method, a Bayesian optimizer is used with and without this method. With this novel method, the optimizer does not encounter any ill-conditioned covariance matrices and the optimality is converged several orders of magnitude deeper than the base case.  </small><br /><br /><small><a href='https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=75371' target='new'>More information on the conference website</a></small></div></span></div>

</body>
</html>
